---
title: "Week 2 Exercises: Logistic and Longitudinal"
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(xaringanExtra)
library(tidyverse)
library(patchwork)
library(ggdist)
xaringanExtra::use_panelset()
qcounter <- function(){
  if(!exists("qcounter_i")){
    qcounter_i <<- 1
  }else{
    qcounter_i <<- qcounter_i + 1
  }
  qcounter_i
}
```

```{r}
#| echo: false
ss = 230168
# ss = round(runif(1,1e3,1e6))
set.seed(ss)
n_groups = 168
npgroup = round(runif(368,2,8))
g = unlist(sapply(1:n_groups, function(x) rep(x,npgroup[x])))
N = length(g)
x = round(runif(N,1,10))
b = sample(letters[1:4],n_groups,T,prob=c(.3,.2,.3,.2))
b = b[g]
res = MASS::mvrnorm(n=n_groups,
                    mu=c(0,0),
                    Sigma=diag(c(3,2))%*%matrix(c(1,.4,.4,1),nrow=2)%*%diag(c(3,2)))
re0 = res[,1]
re  = re0[g]
rex = res[,2]
re_x  = rex[g]
lp = (0 + re) + (1.1 + re_x)*scale(x,center=F)[,1] + 
  1.4*(b=="c") +1.8*(b=="a") +    
  .8*(b=="c")*scale(x,center=F)[,1]+
  -1.1*(b=="d")*scale(x,center=F)[,1]
y = lp + rnorm(N,0,1)
df = data.frame(x = x,g=g, b=b,y=round(scale(y)[,1],1))

mnames = unique(randomNames::randomNames(1e5,which="first"))

df = df |>
  transmute(
    ape = mnames[g],
    age = x,
    species = as.character(factor(b, levels=letters[1:4],labels=c("gorilla","bonobo","chimp","orangutan"))),
    dominance = y
  )
# 
# m1=lmer(dominance ~ age + (1+age|ape),df)
# m2=lmer(dominance ~ age + species + (1+age|ape),df)
# m3=lmer(dominance ~ age * species + (1+age|ape),df)
# any(!is.null(c(m1@optinfo$conv$lme4$messages,
#                m2@optinfo$conv$lme4$messages,
#                m3@optinfo$conv$lme4$messages)))
# library(lme4)
# df$age=df$age-1
# m1=lmer(dominance ~ age + (1+age|ape),df)
# m2=lmer(dominance ~ age + species + (1+age|ape),df)
# m3=lmer(dominance ~ age * species + (1+age|ape),df)
# any(!is.null(c(m1@optinfo$conv$lme4$messages,
#                m2@optinfo$conv$lme4$messages,
#                m3@optinfo$conv$lme4$messages)))
# anova(m1,m2,m3)
# plot(effects::effect("age*species",m3))
# summary(m3)

df$dominance[sample(1:nrow(df),2)] <- c(19.4,-21.2)

spl = df |> count(ape,species) |>
  mutate(
    sp2 = case_when(
      species=="chimp" ~ sample(c("chimp","chimpanzee"),n(),T),
      TRUE ~ species
    )
  )
df = left_join(df,spl)
df[df$ape=="Paige","sp2"] = "gorrila"
df$age[sample(1:nrow(df),3)] <- -99
df = df |> transmute(
  ape, species=sp2, age, dominance
)

# df |> count(ape,species) |> select(-n) |>
#   write_csv(file="../../data/msmr_apespecies.csv")
# df |> select(ape, age, dominance) |>
#   write_csv(file="../../data/msmr_apeage.csv")




# library(lme4)
# m1=lmer(dominance ~ age + (1+age|ape),df)
# m2=lmer(dominance ~ age + species + (1+age|ape),df)
# m3=lmer(dominance ~ age * species + (1+age|ape),df)
# any(!is.null(c(m1@optinfo$conv$lme4$messages,
#                m2@optinfo$conv$lme4$messages,
#                m3@optinfo$conv$lme4$messages)))
# anova(m1,m2,m3)
# plot(effects::effect("age*species",m3))
# summary(m3)
# emmeans::emtrends(m3,var="x") |> summary(infer=c(TRUE))
```


# Great Apes!  

:::frame
__Data: msmr_apespecies.csv__ & __msmr_apeage.csv__  

We have data from a large sample of great apes who have been studied between the ages of 1 to 10 years old (i.e. during adolescence). Our data includes 4 species of great apes: Chimpanzees, Bonobos, Gorillas and Orangutans. Each ape has been assessed on a primate dominance scale at various ages. Data collection was not very rigorous, so apes do not have consistent assessment schedules (i.e., one may have been assessed at ages 1, 3 and 6, whereas another at ages 2 and 8).  

The researchers are interested in examining how the adolescent development of dominance in great apes differs between species.  

Data on the dominance scores of the apes are available at [https://uoepsy.github.io/data/msmr_apeage.csv](https://uoepsy.github.io/data/msmr_apeage.csv){target="_blank"} and the information about which species each ape is are in [https://uoepsy.github.io/data/msmr_apespecies.csv](https://uoepsy.github.io/data/msmr_apespecies.csv){target="_blank"}.  

:::: {.columns}

::: {.column width="45%"}
```{r}
#| echo: false
#| label: tbl-spec1
#| tbl-cap: "Data Dictionary: msmr_apespecies.csv"  
ape_species <- read_csv("../../data/msmr_apespecies.csv")
tibble(
  variable = names(ape_species),
  description = c("Ape Name","Species (Bonobo, Chimpanzee, Gorilla, Orangutan)")
) |> gt::gt()
```
:::
::: {.column width="10%"}

:::
::: {.column width="45%"}
```{r}
#| echo: false
#| label: tbl-spec2
#| tbl-cap: "Data Dictionary: msmr_apeage.csv"  
ape_age <- read_csv("../../data/msmr_apeage.csv")
tibble(
  variable = names(ape_age),
  description = c("Ape Name","Age at assessment (years)","Dominance (Z-scored)")
) |> gt::gt()
```

:::
::::

:::




`r qbegin(qcounter())`
Read in the data and check over it. Do any relevant cleaning/wrangling that might be necessary.   

`r qend()`
`r solbegin(label="1 - reading and joining", slabel=F,show=T, toggle=params$TOGGLE)`
We'll read in both datasets, and then join them together. 
```{r}
library(tidyverse)
library(lme4)
ape_species <- read_csv("https://uoepsy.github.io/data/msmr_apespecies.csv")
ape_age <- read_csv("https://uoepsy.github.io/data/msmr_apeage.csv")
```
Sometimes is handy to check that all our participants are in both datasets:
```{r}
# are all the apes in ape_age also in ape_species?
all(ape_age$ape %in% ape_species$ape)
# and vice versa?
all(ape_species$ape %in% ape_age$ape)
```
Let's join them:  
```{r}
apedat <- full_join(ape_age, ape_species)
head(apedat)
```
`r solend()`
`r solbegin(label="2 - identifying issues", slabel=F,show=T, toggle=params$TOGGLE)`

First off, we can see that we've got some weird typos. Some apes have been identified as "gorrila" but it is actually spelled "gorilla".  
Also, we've got people using two alternatives for the chimps: "chimp" and "chimpanzee". We'll need to combine those.  
```{r}
table(apedat$species)
```


Age looks like it has some weird values (possibly "-99"?), and there are possibly a few outliers in the dominance variable. Given that dominance is standardised, it is _extremely_ unlikely that we would see values around 20.. They're not "impossible", but they're so incredibly unlikely that I'd be more comfortable assuming they are typos: 
```{r echo=c(2,3)}
par(mfrow=c(2,1))
hist(apedat$age, breaks=20)
hist(apedat$dominance, breaks=20)
par(mfrow=c(1,1))
```

Just to see what the most extreme values of dominance are:  
```{r}
# show the biggest 5 absolute values in dominance variable
sort(abs(apedat$dominance), decreasing = TRUE)[1:5]
```

`r solend()`
`r solbegin(label="3 - cleaning up", slabel=F,show=T, toggle=params$TOGGLE)`


```{r}

apedat <- apedat |> 
  mutate(
    # fix species typos
    species = case_when(
      species %in% c("chimp","chimpanzee") ~ "chimp",
      species %in% c("gorilla","gorrila") ~ "gorilla",
      TRUE ~ species
    )
  ) |>
    filter(
      # get rid of ages -99
      age > 0, 
      # keep when dominance is between -5 and 5 
      # (5 here is a slightly arbitrary choice, but you can see from
      # our checks that this will only exclude the two extreme datapoints
      # that are 21.2 and 19.4
      (dominance < 5 & dominance > -5) 
    )

```

`r solend()`

`r qbegin(qcounter())`
How is this data structure "hierarchical" (or "clustered")? What are our level 1 units, and what are our level 2 units?     


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

We have a random sample of $\underbrace{\text{timepoints}}_{\text{level 1}}$ from a random sample of $\underbrace{\text{apes}}_{\text{level 2}}$.  


`r solend()`

`r qbegin(qcounter())`
For how many apes do we have data? How many of each species?  
How many datapoints does each ape have?  


::: {.callout-tip collapse="true"}
#### Hints

We've seen this last week too - counting the different levels in our data. See [2B #getting-to-know-my-monkeys](02b_loglong.html#getting-to-know-my-monkeys){target="_blank"} for an example (with another monkey example!)  

:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

We have `r length(unique(apedat$ape))` apes in our dataset:  
```{r}
length(unique(apedat$ape))
```

Here's how many of each species:  
```{r}
apedat |> 
  group_by(species) |>
  summarise(
   n_apes = n_distinct(ape) 
  )
```

Let's create a table of how many observations for each ape, and then we can create a table _from_ that table, to show how many apes have 2 datapoints, how many have 3, 4, and so on:  
```{r}
table(apedat$ape) |>
  table() |>
  barplot()
```

`r solend()`


`r qbegin(qcounter())`
Make a plot to show how dominance changes as apes get older.  

::: {.callout-tip collapse="true"}
#### Hints

In [2B #exploring-the-data](02b_loglong.html#exploring-the-data){target="_blank"} we made a facet for each cluster (each participant). That was fine because we had only 20 people. In this dataset we have 168! That's too many to facet. The `group` aesthetic will probably help instead!  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Here's a line for each ape, and a facet for each species:  
```{r}
ggplot(apedat, aes(x = age, y = dominance, col = species))+
  geom_line(aes(group = ape)) + 
  facet_wrap(~species) + 
  guides(col="none")
```

It's kind of hard to see the trend for each ape, so let's also make a separate little linear model for each ape:  

```{r}
ggplot(apedat, aes(x = age, y = dominance, col = species))+
  geom_point(alpha=.1) +
  stat_smooth(aes(group=ape),geom="line",method=lm,se=F,alpha=.5) +
  facet_wrap(~species) + 
  guides(col="none")
```

`r solend()`


`r qbegin(qcounter())`
Recenter the `age` variable on 1, which is the youngest ages that we've got data on for any of our species.   

Then fit a model that estimates the differences between primate species in how dominance changes over time.  

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
apedat$age = apedat$age-1 

m.full <- lmer(dominance ~ 1 + age * species + (1 + age | ape), data = apedat)
```

`r solend()`

`r qbegin(qcounter())`
__*Do*__ primate species differ in the growth of dominance?  
Perform an appropriate test/comparison.  

::: {.callout-tip collapse="true"}
#### Hints

This is asking about the `age*species` interaction, which in our model is represented by 3 parameters. To assess the overall question, it might make more sense to do a model comparison.  

:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
m.int <- lmer(dominance ~ 1 + age + species + (1 + age | ape), data = apedat)

anova(m.int, m.full)
```


```{r}
#| echo: false
res = anova(m.int, m.full)

```

:::int

Species differ in how dominance changes over adolescence ($\chi^2(`r res[2,7]`) = `r round(res[2,6],2)`, p = `r format.pval(res[2,8],eps=.001,digits=1)`$).  

:::


`r solend()`

`r qbegin(qcounter())`
Plot the average model predicted values for each age.  

Before you plot.. do you expect to see straight lines? (remember, not every ape is measured at age 2, or age 3, etc).  


::: {.callout-tip collapse="true"}
#### Hints

This is like taking `predict()` from the model, and then then grouping by `age`, and calculating the mean of those predictions. However, we can do this more easily using `augment()` and then some fancy `stat_summary()` in ggplot (see [the lecture](https://uoepsy.github.io/msmr/2324/lectures/msmr_lec02-2_LinearLDA.html#16){target="_blank"}).  


:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Averaging fitted values would give us straight lines _if_ every ape had data at all ages, but in our study we have some apes with only 2 data points, and each ape has different set of ages (e.g., one ape might be measured at age 3, 6, and 10, another ape might be at ages 2 and 16).  

```{r}
library(broom.mixed)

augment(m.full) |>
ggplot(aes(age,dominance, color=species)) +
  # the point ranges are our observations
  stat_summary(fun.data=mean_se, geom="pointrange") + 
  # the lines are our average predictions  
  stat_summary(aes(y=.fitted, linetype=species), fun=mean, geom="line")
```

`r solend()`

`r qbegin(qcounter())`
Plot the model based fixed effects:  
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
effects::effect("age*species", m.full, xlevels=10) |>
  as.data.frame() |>
  ggplot(aes(x=age+1,y=fit,col=species))+
  geom_line(lwd=1)+
  geom_ribbon(aes(ymin=lower,ymax=upper,fill=species),col=NA,alpha=.3) +  
  scale_color_manual(values=c("grey30","black","grey50","darkorange")) +
  scale_fill_manual(values=c("grey30","black","grey50","darkorange")) +
  facet_wrap(~species) + 
  guides(col="none",fill="none") +
  labs(x="Age (years)")
  
```


`r solend()`

`r qbegin(qcounter())`
Interpret each of the fixed effects from the model (you might also want to get some p-values or confidence intervals).  

::: {.callout-tip collapse="true"}
#### Hints

Each of the estimates should correspond to part of our plot from the previous question.  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Let's get some confidence intervals:  
```{r}
confint(m.full, method="profile",
        parm = "beta_")
```


```{r}
#| echo: false
cis = confint(m.full, method="profile",
        parm = "beta_")
sign = ifelse(cis[,1]>0|cis[,2]<0,1,0)

tidy(m.full) |>
  filter(effect=="fixed") |>
  transmute(term, est=round(estimate,2),
            CI = paste0("[",round(cis[,1],2),", ",round(cis[,2],2),"]")) |>
  mutate(
    CI = ifelse(sign,paste0(CI,"*"),CI)
  ) |> 
  mutate(
    interpretation = c(
      "estimated dominance of 1 year old bonobos (at left hand side of plot, bonobo line is lower than 0)",
      "estimated change in dominance score for every year older a bonobo gets (slope of bonobo line)",
      "estimated difference in dominance scores at age 1 between bonobos and chimps (at left hand side of plot, chimp line is higher than bonobo line)",
      "estimated difference in dominance scores at age 1 between bonobos and gorillas (at left hand side of plot, gorilla line is higher than bonobo line)",
      "no significant difference in dominance scores at age 1 between bonobos and orangutans (at the left hand side of our plot, orangutan line is similar height to bonobo line)",
      "no significant difference between chimps and bonobos in the change in dominance for every year older (slope of chimp line is similar to slope of bonobo line)",
      "no significant difference between gorillas and bonobos in the change in dominance for every year older (slope of gorilla line is similar to slope of bonobo line)",
      "estimated difference between orangutans and bonobos in the change in dominance for every year older (slope of orangutan line is less steep than slope of bonobo line)"
    )
  ) |> gt::gt()
```


`r solend()`

<br>

<div class="divider div-transparent div-dot"></div>

# Trolley problems


```{r}
#| echo: false
ss = 173223
#while(TRUE){
#  ss = round(runif(1,1e3,1e6))
  set.seed(ss)
  n_groups = 120
  npgroup = rep(12,n_groups)
  g = unlist(lapply(1:n_groups, function(x) rep(x,npgroup[x])))
  N = length(g)
  b = round(runif(n_groups,18,45))
  b = b[g]
  x = rep(rep(1:3,e=4),n_groups)
  x2 = rep(rep(letters[4:5],6),n_groups)
  res = MASS::mvrnorm(n=n_groups,
                      mu=c(0,0,0),
                      Sigma=diag(c(4,2,2)) %*% 
                        matrix(c(1,.4,.3,.4,1,.4,.3,.4,1),nrow=3) %*% 
                        diag(c(4,2,2)))
  re0 = res[,1]
  re  = re0[g]
  rex = res[,2]
  re_x  = rex[g]
  rex2 = res[,3]
  re_x2  = rex2[g]
  lp = (0 + re) + (.1*b) + 
    (-2 + re_x)*x + (2 + re_x2)*(x2=="e") +
    (2*(x-2)*(x2=="e"))
  y = lp + rnorm(N,0,1)
  y_bin = rbinom(N,1, plogis(.75+scale(lp)))
  df = data.frame(x=x,x2=x2,g=g, b=b,y=y,y_bin=y_bin)
  mnames = unique(randomNames::randomNames(1e5,which="first"))
  df = df |> transmute(
    frame = factor(x, levels=c("1","2","3"),
                   labels=c("positive","neutral","negative")),
    lives = factor(x2, levels=c("d","e"),labels=c("5lives","15lives")),
    age = b,
    PID = paste0("PPT_",g),
    lever = y_bin
  )
#   m = glmer(lever ~ scale(age) + frame*lives +
#               (1+frame+lives|PID),data=df,family=binomial,
#             control=glmerControl(optimizer = "bobyqa"))
#   if(is.null(m@optinfo$conv$lme4$messages)){break}
#   m = glmer(lever ~ scale(age) + frame*lives +
#               (1+lives|PID),data=df,family=binomial,
#             control=glmerControl(optimizer = "bobyqa"))
#   if(is.null(m@optinfo$conv$lme4$messages)){break}
# }
# sjPlot::plot_model(m,type="int")
# summary(m)
trolley <- df |> select(PID,frame,lives,lever)
# write_csv(trolley, file="../../data/msmr_trolley.csv")
```

:::frame
__Data: msmr_trolley.csv__  

The "Trolley Problem" is a thought experiment in moral philosophy that asks you to decide whether or not to pull a lever to divert a trolley. Pulling the lever changes the trolley direction from hitting 5 people to a track on which it will hit one person.  

```{r}
#| echo: false
knitr::include_graphics("images/trolley.png")
```

Previous research has found that the "framing" of the problem will influence the decisions people make: 

```{r}
#| echo: false
tribble(
  ~`positive frame`,~`neutral frame`,~`negative frame`,
  "5 people will be saved if you pull the lever; one person on another track will be saved if you do not pull the lever. All your actions are legal and understandable. Will you pull the lever?","5 people will be saved if you pull the lever, but another person will die. One people will be saved if you do not pull the lever, but 5 people will die. All your actions are legal and understandable. Will you pull the lever?",
  "One person will die if you pull the lever. 5 people will die if you do not pull the lever. All your actions are legal and understandable. Will you pull the lever?"
) |> gt::gt()
```

We conducted a study to investigate **whether the framing effects on moral judgements depends upon the stakes (i.e. the number of lives saved)**.  

`r n_distinct(trolley$PID)` participants were recruited, and each gave answers to 12 versions of the thought experiment. For each participant, four versions followed each of the positive/neutral/negative framings described above, and for each framing, 2 would save 5 people and 2 would save 15 people.  

The data are available at [https://uoepsy.github.io/data/msmr_trolley.csv](https://uoepsy.github.io/data/msmr_trolley.csv){target="_blank"}.  

```{r}
#| echo: false
#| label: tbl-trolley
#| tbl-cap: "Data Dictionary: trolley.csv"
tibble(
  variable = names(trolley),
  description = c(
    "Participant ID",
    "framing of the thought experiment (positive/neutral/negative",
    "lives at stake in the thought experiment (5 or 15)",
    "Whether or not the participant chose to pull the lever (1 = yes, 0 = no)")
) |> gt::gt()
```



:::

`r qbegin(qcounter())`
Read in the data and check over how many people we have, and whether we have complete data for each participant.  

::: {.callout-tip collapse="true"}
#### Hints

I would maybe try `data |> group_by(participant) |> summarise()`, and then use the `n_distinct()` function to count how many "things" each person sees (e.g., [2B #example](02b_loglong.html#example){target="_blank"}). 

:::


`r qend()`
`r solbegin(show=TRUE, toggle=params$TOGGLE)`

```{r}
trolley <- read_csv("https://uoepsy.github.io/data/msmr_trolley.csv")
head(trolley)
```

How many participants?
```{r}
length(unique(trolley$PID))
```

How many trials for each participant in each condition.  
We can, for each participant, count how many trials they have in total, how many "frames" they see, how many "lives" they see, and how many "frame x lives" combinations they see:  
```{r}
trolley |>
  group_by(PID) |>
  summarise(
    n_trials = n(),
    n_frame = n_distinct(frame),
    n_lives = n_distinct(lives),
    n_combn = n_distinct(frame,lives)
  )
```

If everybody gets the same here (as we can see they do below), then everyone has complete data!  

```{r}
trolley |>
  group_by(PID) |>
  summarise(
    n_trials = n(),
    n_frame = n_distinct(frame),
    n_lives = n_distinct(lives),
    n_combn = n_distinct(frame,lives)
  ) |>
  summary()
```


`r solend()`

`r qbegin(qcounter())`
Construct an appropriate plot to summarise the data in a suitable way to illustrate the research question.  


::: {.callout-tip collapse="true"}
#### Hints

Something making use of `stat_summary()` to give proportions, a bit like the plot in [2B #getting-to-know-my-monkeys](02b_loglong.html#getting-to-know-my-monkeys){target="_blank"}?  

:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Here is a plot of proportions of trials in which the lever was pulled, split by how the problem was framed, and the number of lives saved:  
```{r}
ggplot(trolley, aes(x=frame, y=lever, col=lives)) +
  stat_summary(geom="pointrange", size=1, 
               position=position_dodge(width=.2)) 
  
```

`r solend()`

`r qbegin(qcounter())`
Fit a model to assess the research aims.  
Don't worry if it gives you an error, we'll deal with that in a second.  


::: {.callout-tip collapse="true"}
#### Hints

- Remember, a good way to start is to split this up into 3 parts: 1) the outcome and fixed effects, 2) the grouping structure, and 3) the random slopes.  
- fitting (or attempting to fit!) `glmer` models might take time!  


:::

`r qend()`
`r solbegin(label="1 - fixed", slabel=F,show=T, toggle=params$TOGGLE)`

The researchers are *"interested in whether the framing effects on moral judgements depends upon the stakes (i.e. the number of lives saved)"*.  

"the framing effect on moral judgements" here is operationalised as  
```{r}
#| eval: false
lever ~ frame
```
and the wording "depends upon the stakes" means that we want to know if that effect of frame "is different for" the situations when lives = 5, vs lives = 15 - i.e. we need the interaction!  
```{r}
#| eval: false
lever ~ frame * lives
```

The outcome here is lever pulled (yes v no), so it's a binary variable!  

```{r}
#| eval: false
glmer(lever ~ frame * lives + ....
      ....,  
      data = trolley, family = binomial)
```

`r solend()`
`r solbegin(label="2 - grouping", slabel=F,show=T, toggle=params$TOGGLE)`

We know that we have multiple observations for each participant, and those participants are just a random sample (it's not something we're interested in testing, we would like to model participant differences as random variation).  
```{r}
#| eval: false
glmer(lever ~ frame * lives + ....
      (1 + .... | PID),  
      data = trolley, family = binomial)
```


`r solend()`
`r solbegin(label="3 - random", slabel=F,show=T, toggle=params$TOGGLE)`

Finally, what effects _could_ theoretically vary between our participants?  
Every participant saw everything (i.e. both `frame` and `lives` are "within participant" variables). 

In theory, all of these are possible given our design:  

- the effect of frame on probability of pulling the lever could vary between participants
- the effect of number of lives on probability of pulling the lever could vary between participants
- the amount by which number of lives influences the effect of frame on pulling the lever could vary between participants

So we could theoretically try and fit this model:  
```{r}
#| eval: false
mod1 <- glmer(lever ~ frame * lives + 
      (1 + frame * lives | PID),  
      data = trolley, family = binomial)
```
<p style="color:red;">
Warning messages:<br>
1: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
  failure to converge in 10000 evaluations<br>
2: In optwrap(optimizer, devfun, start, rho\$lower, control = control,  :
  convergence code 4 from Nelder_Mead: failure to converge in 10000 evaluations<br>
3: In checkConv(attr(opt, "derivs"), opt\$par, ctrl = control\$checkConv,  :
  Model failed to converge with max|grad| = 0.0795145 (tol = 0.002, component 1)
</p>
`r solend()`

`r qbegin(qcounter())`
This is probably the first time we've had to deal with a model not converging.  

While sometimes changing the optimizer can help, more often than not, the model we are trying to fit is just too complex. Often, the groups in our sample just don't vary enough for us to estimate a random slope.  

The aim here is to simplify our random effect structure in order to obtain a converging model, but be careful not to over simplify.  

Try it now. What model do you end up with? (You might not end up with the same model as each other, which is fine. These methods don't have "cookbook recipes"!)

::: {.callout-tip collapse="true"}
#### Hints

you could think of the interaction as the 'most complex' part of our random effects, so you might want to remove that first.  

:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

This model still does not converge:  
```{r}
mod2 <- glmer(lever ~ frame * lives + 
      (1 + frame + lives | PID),  
      data = trolley, family = binomial)
```
<p style="color:red;">
Warning message:<br>
In checkConv(attr(opt, "derivs"), opt\$par, ctrl = control\$checkConv,  :
  Model failed to converge with max|grad| = 0.00734804 (tol = 0.002, component 1)
</p>

We have a choice here - do we remove `frame|PID` or `lives|PID`? One practical point is that each participant has only 4 observations for each `frame` type, but they have 6 observations for each `lives` type, which might make it easier to fit.  
```{r}
mod3 <- glmer(lever ~ frame * lives + 
      (1 + lives | PID),  
      data = trolley, family = binomial)
```
Hooray! it converges!  

`r solend()`

`r qbegin(qcounter())`
Plot the predicted probabilities from your model for each combination of `frame` and `lives`.  
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
library(effects)
effect("frame*lives", mod3) |>
  as.data.frame() |>
  ggplot(aes(x = frame, y = fit, col = lives)) +
  geom_pointrange(aes(ymin=lower,ymax=upper),
                  position=position_dodge(width=.2),
                  size=1)+
  labs(y="probability of pulling the lever")
```


`r solend()`

<!-- `r qbegin(qcounter())` -->
<!-- Compute odds ratios and create some confidence intervals, then interpret them.   -->


<!-- ::: {.callout-tip collapse="true"} -->
<!-- #### Hints -->

<!-- Odds ratios are confusing, so take the lead from your plot about what goes up/down etc.   -->
<!-- The default of profile likelihood confidence intervals might take a while to compute, so you could choose the Wald method instead (see [2B #interpretation](02b_loglong.html#interpretation){target="_blank"}).   -->

<!-- ::: -->


<!-- `r qend()` -->
<!-- `r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)` -->

<!-- ```{r} -->
<!-- cbind( -->
<!--   fixef(mod3), # the fixed effects -->
<!--   confint(mod3, method="Wald", parm="beta_") # Wald CIs for fixed effects -->
<!-- ) |> -->
<!--   exp() -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| echo: false -->
<!-- cbind( -->
<!--   fixef(mod3), # the fixed effects -->
<!--   confint(mod3, method="Wald", parm="beta_") # Wald CIs for fixed effects -->
<!-- ) |> -->
<!--   exp() |> as.data.frame() |> -->
<!--   rownames_to_column() |> -->
<!--   transmute( -->
<!--     term = rowname, OR=round(V1,2), -->
<!--     CI = paste0("[", -->
<!--                 round(`2.5 %`,2),", ", -->
<!--                 round(`97.5 %`,2),"]" -->
<!--     ), -->
<!--     interpretation = c( -->
<!--       "Odds of pulling the lever when in a positive framed problem with the potential of saving 5 lives", -->
<!--       paste0("With 5 lives at stake, a neutral framing is associated with ",round(exp(fixef(mod3))[2],2)," times the odds of pulling the lever in comparison to a positive framing"), -->
<!--       paste0("With 5 lives at stake, a negative framing is associated with ",round(exp(fixef(mod3))[3],2)," times the odds of pulling the lever in comparison to a positive framing"), -->
<!--       "In a positive framing, the number of lives at stake is not associated with a change in the odds of pulling the lever", -->
<!--       paste0("In the neutral framing, the 15 vs 5 lives The neutral vs positive framing difference is increase  ",round(exp(fixef(mod3))[2],2)," times the odds of pulling the lever in comparison to a positive framing"), -->
<!--     ) -->
<!--   )  -->
<!-- ``` -->

<!-- `r solend()` -->


<br>

<div class="divider div-transparent div-dot"></div>


# Optional extra: Novel Word Learning


:::frame
__Data: nwl.Rdata__ 

```{r}
load(url("https://uoepsy.github.io/msmr/data/nwl.RData"))
```

In the `nwl` data set (accessed using the code above), participants with aphasia are separated into two groups based on the general location of their brain lesion: anterior vs. posterior. There is data on the numbers of correct and incorrect responses participants gave in each of a series of experimental blocks. There were 7 learning blocks, immediately followed by a test. Finally, participants also completed a follow-up test.
<br>
Data were also collect from healthy controls. 
<br>
@fig-nwl shows the differences between lesion location groups in the average proportion of correct responses at each point in time (i.e., each block, test, and follow-up)

```{r}
#| label: fig-nwl
#| echo: false
#| fig.cap: "Differences between groups in the average proportion of correct responses at each block"
load(url("https://uoepsy.github.io/msmr/data/nwl.RData"))
ggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, 
                                            color=lesion_location, 
                                            shape=lesion_location)) +
  #geom_line(aes(group=ID),alpha=.2) + 
  stat_summary(fun.data=mean_se, geom="pointrange") + 
  stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), 
                           fun=mean, geom="line") + 
  geom_hline(yintercept=0.5, linetype="dashed") + 
  geom_vline(xintercept=c(7.5, 8.5), linetype="dashed") + 
  scale_x_continuous(breaks=1:9, labels=c(1:7, "Test", "Follow-Up")) + 
  theme_bw(base_size=10) + 
  labs(x="Block", y="Proportion Correct", shape="Lesion\nLocation", color="Lesion\nLocation")
```


```{r}
#| echo: false
data.frame(
  variable = names(nwl),
  description = c("Whether participant is a stroke patient ('patient') or a healthy control ('control')", "Location of brain lesion: anterior vs posterior","Experimental block (1-9). Blocks 1-7 were learning blocks, immediately followed by a test in block 8. Block 9 was a follow-up test at a later point","Proportion of 30 responses in a given block that the participant got correct","Number of responses (out of 30) in a given block that the participant got correct","Number of responses (out of 30) in a given block that the participant got incorrect","Participant Identifier","Experimental phase, corresponding to experimental block(s): 'Learning', 'Immediate','Follow-up'")
) |> gt::gt()
```


:::


`r qbegin(qcounter())`
Load the data. Take a look around. Any missing values? Can you think of why?  
`r qend()`

`r solbegin(show=TRUE, toggle=params$TOGGLE)`

```{r}
load(url("https://uoepsy.github.io/msmr/data/nwl.RData"))
summary(nwl)
```

The only missing vales are in the lesion location, and it's probably because the healthy controls don't have any lesions. There may also be a few patients for which the lesion_location is missing, but this should be comparatively fewer values compared to controls.

The following command creates a two-way frequency table showing the number of controls or patients by lesion location, confirming that controls only have missing values (NAs) and only 9 patients have missing values:

```{r}
table(nwl$group, nwl$lesion_location, useNA = "ifany")
```

`r solend()`


`r qbegin(qcounter())`
Our broader research aim today is to compare the two lesion location groups (those with anterior vs. posterior lesions) with respect to their accuracy of responses over the course of the study.  

- What is the outcome variable? 

::: {.callout-tip collapse="true"}
#### Hints

Think carefully: there might be several variables which either fully or partly express the information we are considering the "outcome" here. 
We saw this back in [USMR](https://uoepsy.github.io/usmr/2324/labs/10a_glm.html#fitting-glm-in-r){target="_blank"} with the `glm()`!  

:::


`r qend()`
`r solbegin(show=TRUE, toggle=params$TOGGLE)`
The outcome here is (in words) the proportion of correct answers or, equivalently, the probability of answering correctly. A proportion/probability can only vary between 0 and 1 and, as such, we cannot use traditional linear regression or we could end up with predictions outside of the [0, 1] range.

As said, the outcome is the proportion of correct answers in each block. This makes it tempting to look at the variable called `PropCorrect`, but this is encoded as a proportion. We have learned to use logistic models, but these require either:

- a binary outcome variable, where the values are 0s or 1s
- a binomial outcome variable, where the values are aggregated counts of 1s and 0s 

__Binary data__. In the case below you would use the specification `correct ~ ...`:

```{r echo=FALSE}
tibble(participant = c(1,1,1),
       question=c(1,2,3),
       correct=c(1,0,1)) %>%
    rbind(rep("...",3)) %>%
    gt::gt()
```

__Binomial data__. You would use the specification `cbind(num_successes, num_failures)` which, in the case below, would be:

`cbind(questions_correct, questions_incorrect) ~ ...`

```{r echo=FALSE}
tibble(participant = c(1,2,3),
       questions_correct=c(2,1,3),
       questions_incorrect=c(1,2,0)) %>% 
    rbind(rep("...",3)) %>% 
    gt::gt()
```

`r solend()`

`r qbegin(qcounter())`
> **Research Question 1:**  
> Is the learning rate (training blocks) different between the two lesion location groups?


::: {.callout-tip collapse="true"}
#### Hints

- Do we want `cbind(num_successes, num_failures)`?

- Ensure you are running models on only the data we are actually interested in. 

    + Are the healthy controls included in the research question under investigation?
    + Are the testing blocks included in the research question, or only the learning blocks?

- We could use model comparison via likelihood ratio tests (using `anova(model1, model2, model3, ...)`. For this question, we could compare:

    + A model with just the change over the sequence of blocks
    + A model with the change over the sequence of blocks *and* an overall difference between groups
    + A model with groups differing with respect to their change over the sequence of blocks

- What about the random effects part?  
    
    1. What are our observations grouped by? 
    2. What variables can vary within these groups? 
    3. What do you want your model to allow to vary within these groups?

:::

`r qend()`
`r solbegin(label="1 - answers to the hints", slabel=F,show=T, toggle=params$TOGGLE)`

- Do we want `cbind(num_successes, num_failures)`?

    + Yes, we don't a binary variable with correct/incorrect questions but the binomial variables NumCorrect and NumError representing, respectively, the aggregated count (out of 30) of correct and incorrect questions. As such, we will need the following: `cbind(NumCorrect, NumError)`

- Ensure you are running models on only the data we are actually interested in. 

    + The healthy controls are not included in the research question under investigation, so we will exclude them.
    + We are only interested in the learning blocks, and we will exclude the testing blocks (block > 7) 
    + You might want to store this data in a separate object, but in the code for the solution we will just use `filter()` *inside* the `glmer()`.   
  
- A model with just the change over the sequence of blocks:
    - **outcome ~ block**
- A model with the change over the sequence of blocks *and* an overall difference between groups:
    - **outcome ~ block + lesion_location**
- A model with groups differing with respect to their change *over the sequence of blocks:
    - **outcome ~ block * lesion_location**
    
- What are our observations grouped by? 
    - repeated measures by-participant. i.e., the `ID` variable
- What variables can vary within these groups? 
    - `Block` and `Phase`. Be careful though - you can create the `Phase` variable out of the `Block` variable, so really this is just one piece of information, encoded differently in two variables. 
    - The other variables (`lesion_location` and `group`) do **not** vary for each ID. Lesions don't suddenly change where they are located, nor do participants swap between being a patient vs a control (we don't need the group variable anyway as we are excluding the controls).  
What do you want your model to allow to vary within these groups?
    - Do you think the change over the course of the blocks is **the same** for everybody? Or do you think it varies? Is this variation important to think about in terms of your research question?   
    
`r solend()`
`r solbegin(label="2 - modelling", slabel=F,show=T, toggle=params$TOGGLE)`

```{r}
m.base <- glmer(cbind(NumCorrect, NumError) ~ block + (block | ID), 
                data = filter(nwl, block < 8, !is.na(lesion_location)),
                family=binomial)

m.loc0 <- glmer(cbind(NumCorrect, NumError) ~ block + lesion_location + (block | ID), 
                data=filter(nwl, block < 8, !is.na(lesion_location)),
                family=binomial)

m.loc1 <- glmer(cbind(NumCorrect, NumError) ~ block * lesion_location + (block | ID), 
                data=filter(nwl, block < 8, !is.na(lesion_location)),
                family=binomial)


anova(m.base, m.loc0, m.loc1, test="Chisq")
```
:::int
No significant difference in learning rate between groups ($\chi^2(1)=2.2, p = 0.138$).
:::

`r solend()`

`r qbegin(qcounter())`
> **Research Question 2**  
> In the testing phase, does performance on the immediate test differ between lesion location groups, and does the retention from immediate to follow-up test differ between the two lesion location groups?

Let's try a different approach to this. Instead of fitting various models and comparing them via likelihood ratio tests, just fit the one model which could answer both parts of the question above.  


::: {.callout-tip collapse="true"}
#### Hints

- This might required a bit more data-wrangling beforehand. Think about the order of your factor levels (alphabetically speaking, "Follow-up" comes before "Immediate")!

:::

`r qend()`
`r solbegin(show=TRUE, toggle=params$TOGGLE)`
```{r}
nwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) %>%
    mutate(
        Phase = factor(Phase), 
        Phase = fct_relevel(Phase, "Immediate")
    )

m.recall.loc <- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID), 
                      nwl_test, family="binomial")

summary(m.recall.loc)
```


__Note 1__: 

In the above, we have made sure to select the patients by specifying `!is.na(lesion_location)`, meaning that we want those rows where the lesion location is not missing. As a reminder `!` is the negation function (not). As we saw in the earlier question, this excludes the 126 healthy controls, as well as the 9 patients for which we have missing values (NAs).

__Note 2__:  

We didn't specify `(Phase | ID)` as the random effect because each participant only has 2 data points for Phase, and there is only one line that fits two data points. In other words, there is only one possible way to fit those two data points. As such, as each group of 2 points will have a perfect line fit, and the residuals $\varepsilon_{ij}$ will all be 0. As a consequence of this, the residuals will have no variability as they are all 0, so $\sigma_{\epsilon}$ is 0 which in turn leads to problem with estimating the model coefficients.

```{r}
subset(nwl_test, ID == 'patient15')
```

If you try using `(Phase | ID)` as random effect, you will see the following message:

`boundary (singular) fit: see help('isSingular')`

`r solend()`

`r qbegin(qcounter())`

1. In `family = binomial(link='logit')`. What function is used to relate the linear predictors in the model to the expected value of the response variable?  
2. How do we convert this into something more interpretable?  

`r qend()`
`r solbegin(show=TRUE, toggle=params$TOGGLE)`
 
1. The link function is the `logit`, or log-odds (other link functions are available).

2. To convert log-odds to odds, we can use `exp()`, to get odds and odds ratios.  

`r solend()`

`r qbegin(qcounter())`
Make sure you pay attention to trying to interpret each fixed effect from your models.  
These can be difficult, especially when it's logistic, and especially when there are interactions.  

- What is the increase in the odds of answering correctly in the immediate test if you were to have a posterior legion instead of an anterior legion?  

<!-- `r optbegin("Optional help: Our Solution to A4", olabel=F, toggle=params$TOGGLE)` -->
<!-- ```{r eval=F} -->
<!-- nwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) %>% -->
<!--   mutate( -->
<!--     Phase = fct_relevel(factor(Phase),"Immediate") -->
<!--   ) -->

<!-- m.recall.loc <- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID),  -->
<!--                   nwl_test, family="binomial") -->
<!-- ``` -->
<!-- `r optend()` -->

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
exp(fixef(m.recall.loc))
```


* `(Intercept)` ==> Anterior lesion group performance in immediate test. This is the odds of them answering correctly in the immediate test. 
* `PhaseFollow-up`  ==> Change in performance (for someone with an anterior lesion) from immediate to follow-up test. 
* `lesion_locationposterior` ==> Change in performance in immediate test were a patient to have a posterior lesion instead of an anterior lesion. 
* `PhaseFollow-up:lesion_locationposterior` ==> How change in performance from immediate to follow-up test would differ were a patient to have a posterior lesion instead of an anterior lesion.  

```{r}
exp(fixef(m.recall.loc))[3]
```

:::int
Having a posterior lesions is associated with `r round(exp(fixef(m.recall.loc))[3],2)` times the odds of answering correctly in the immediate test compared to having an anterior lesion.  
:::

`r solend()`

`r qbegin(qcounter())`
Recreate the visualisation in @fig-nwl2.  

```{r}
#| label: fig-nwl2
#| echo: false
#| fig-cap: "Differences between groups in the average proportion of correct responses at each block"
load(url("https://uoepsy.github.io/msmr/data/nwl.RData"))
ggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, 
                                                 color=lesion_location, 
                                                 shape=lesion_location)) +
    #geom_line(aes(group=ID),alpha=.2) + 
    stat_summary(fun.data=mean_se, geom="pointrange") + 
    stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), 
                 fun=mean, geom="line") + 
    geom_hline(yintercept=0.5, linetype="dashed") + 
    geom_vline(xintercept=c(7.5, 8.5), linetype="dashed") + 
    scale_x_continuous(breaks=1:9, 
                       labels=c(1:7, "Test", "Follow-Up")) + 
    theme_bw(base_size=10) + 
    labs(x="Block", y="Proportion Correct", 
         shape="Lesion\nLocation", color="Lesion\nLocation")
```

`r qend()`
`r solbegin(show=TRUE, toggle=params$TOGGLE)`
```{r}
ggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, 
                                                 color=lesion_location, 
                                                 shape=lesion_location)) +
    #geom_line(aes(group=ID),alpha=.2) + 
    stat_summary(fun.data=mean_se, geom="pointrange") + 
    stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), 
                 fun=mean, geom="line") + 
    geom_hline(yintercept=0.5, linetype="dashed") + 
    geom_vline(xintercept=c(7.5, 8.5), linetype="dashed") + 
    scale_x_continuous(breaks=1:9, 
                       labels=c(1:7, "Test", "Follow-Up")) + 
    theme_bw(base_size=10) + 
    labs(x="Block", y="Proportion Correct", 
         shape="Lesion\nLocation", color="Lesion\nLocation")
```
`r solend()`


<!-- `r qbegin(qcounter())` -->
<!-- This code is that we used to answer the question above, only we have edited it to change lesion location to be fitted with "sum contrasts".   -->

<!-- ```{r echo=TRUE} -->
<!-- nwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) %>% -->
<!--     mutate( -->
<!--         Phase = factor(Phase), -->
<!--         Phase = fct_relevel(Phase, "Immediate") -->
<!--     ) -->

<!-- m.recall.loc.effcoding <-  -->
<!--     glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID),  -->
<!--           contrasts = list(lesion_location = "contr.sum"), -->
<!--           data = nwl_test, family="binomial") -->
<!-- ``` -->


<!-- The interpretation of this is going to get pretty tricky - we have a logistic regression, and we have different coding scheme for our categorical predictor, and we have an interaction.. &#x1f92f;   -->

<!-- Can you work out the interpretation of the fixed effects estimates?   -->

<!-- `r qend()` -->
<!-- `r solbegin(show=TRUE, toggle=params$TOGGLE)` -->

<!-- * `(Intercept)` ==> Overall performance in immediate test. This is the overall log-odds of answering correctly in the immediate test.  -->
<!-- * `PhaseFollow-up`  ==> Average change in performance from immediate to follow-up test.  -->
<!-- * `lesion_location1` ==> Anterior lesion group performance in immediate test relative to *overall average* performance in immediate test -->
<!-- * `PhaseFollow-up:lesion_location1` ==> Change in performance from immediate to follow-up test, anterior lesion group relative to overall average -->


<!-- **???**   -->
<!-- How do we know that `lesion_location1` is the *anterior* and not the *posterior* lesion group?  -->
<!-- We need to check the what the contrasts look like:   -->
<!-- ```{r} -->
<!-- contrasts(nwl_test$lesion_location) <- "contr.sum" -->
<!-- contrasts(nwl_test$lesion_location) -->
<!-- ``` -->
<!-- Because there are only two levels to this variable, the estimate will simply flip sign (positive/negative) depending on which way the contrast is leveled.   -->


<!-- ::: {.callout-note collapse="true"} -->
<!-- #### I liked my coefficients being named properly? -->

<!-- ```{r} -->
<!-- colnames(contrasts(nwl_test$lesion_location)) <- "PeppaPig" -->

<!-- contrasts(nwl_test$lesion_location) -->

<!-- modeltest <-  -->
<!--     glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID), -->
<!--           nwl_test, family="binomial") -->
<!-- summary(modeltest)$coefficients -->
<!-- ``` -->

<!-- ::: -->

<!-- `r solend()` -->


