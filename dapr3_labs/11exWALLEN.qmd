---
title: "W11 Exercises"
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(xaringanExtra)
library(tidyverse)
library(patchwork)
library(psych)
xaringanExtra::use_panelset()
qcounter <- function(){
  if(!exists("qcounter_i")){
    qcounter_i <<- 1
  }else{
    qcounter_i <<- qcounter_i + 1
  }
  qcounter_i
}
```


`r qbegin("Q1 - EFA [15 marks]", qlabel=F)`
```{r}
#| echo: false
m = "
  lv1 =~ .8*y1 + .6*y2 + .6*y3 + .7*y4
  lv2 =~ .7*y5 + .8*y6 + .9*y7 + .7*y8
  lv3 =~ .8*y9 + .8*y10 + .9*y11 + .4*y4
  lv4 =~ .9*y12
  lv1 ~~.2*lv2
  lv1 ~~.2*lv3
  lv2 ~~.2*lv2
"
eseed=round(runif(1,1e3,1e6))
set.seed(167807)
df = lavaan::simulateData(m,sample.nobs = 500)
library(psych)
somedata <- df
mm = fa(somedata, nfactors = 4, rotate="oblimin",fm="ml")
```

Below are the results of a data reduction of a set of 12 items assessing environmental conscientiousness. Participants are asked to respond to each statement on a 5-point likert scale from "Strongly Disagree" to "Strongly Agree". 

Based on the results and the item descriptions below, provide an interpretation of the factor solution. Your description should include: 

- Comment on the numerical solution **[6 marks]**
- Discussion of suitability of the selected number of factors **[6 marks]**
- An attempt to define the factors **[3 marks]**


```{r}
#| echo: false
#| out-width: "60%"
knitr::include_graphics("images/mock/efa.png")
```

::::{.columns}
:::{.column width="50%"}

```{r}
#| echo: false
tribble(
  ~item, ~wording,
  "y1","I recycle regularly",
  "y2","I use eco-friendly transportation",
  "y3","I buy sustainable products",
  "y4","I know how to reduce my carbon footprint",
  "y5","Protecting resources matters to me",
  "y6","I care about protecting the environment"
) |> gt::gt()
```
:::

:::{.column width="50%"}

```{r}
#| echo: false
tribble(
  ~item, ~wording,
  "y7","I feel responsible for my environmental impact",
  "y8","I am worried about climate change effects",
  "y9","I know about the harm of single-use plastics",
  "y10","I know how deforestation affects climate change",
  "y11","I know about relevant environmental policies",
  "y12","Wildlife destruction concerns me deeply",
) |> gt::gt()
```
:::
::::



`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

- 12 items, 4 factors extracted. explains 29% variance
- Factors ML2 & ML1 both have $\geq 3$ salient/primary loadings
    - salient = $\geq |0.3|$
- Factors ML3 & ML4: both have only 1 item with salient loading
- 3rd factor explaining only 6%, 4th factor only 2%
- SSloadings for ML3 & ML4 are <1
- 3 complex items (y4, y5, y6)
- some items (y5,y6) have no salient loadings
- Factors ML1,2,3 correlated weak-moderate
- Factor ML4 not strongly correlated with others
- probably overextracting (too many factors)
- main pointer = low variance expl of ML3 & ML4, plus not enough items
- complex items y5 & y6 are spread across ML3 & ML4 - a 3 factor solution may well make more sense
- item y4 = one to keep an eye on
- ML1 = "environmental knowledge"
- ML2 = "environmental behaviours"
- ML3/4 combined look like "environmental concern"


`r solend()`


`r qbegin("Q2 - SSloadings [4 marks]", qlabel=F)`

Calculate the 6 values missing from the table below: SSloadings **[2 marks]** and proportion & cumulative variance **[2 marks]**.  

```{r}
#| echo: false
set.seed(67768)
nitem <- 5
A <- matrix(runif(nitem^2,.41,1)*2-1, ncol=nitem) 
scor <- t(A) %*% A
df <- MASS::mvrnorm(n=220,mu=rep(0,5),Sigma = scor) |> as.data.frame()
loadings = psych::principal(df,nfactors=2, rotate="none")$loadings[,1:2]
loadings[1:4,1] = round(loadings[1:4,1],1)
loadings[5,1] = round(loadings[5,1],2)
loadings[c(1,3:5),2] = round(loadings[c(1,3:5),2],1)
loadings[2,2] = round(loadings[2,2],2)

vac <- psych::principal(df,nfactors=2, rotate="none")$Vaccounted[1:3,]
vac[1:3,1:2] <- " __ "

rownames(loadings) = paste0("item",1:5)
loadings
noquote(vac)
```

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Table filled in:
```{r}
#| echo: false
vv = as.data.frame(rbind(
  apply(loadings,2,\(x) sum(x^2)),
  apply(loadings,2,\(x) sum(x^2))/5,
  cumsum(apply(loadings,2,\(x) sum(x^2))/5)
))
rownames(vv) = rownames(vac)
vv
```

How?   
start by squaring all the numbers, and sum the columns to give us SSloadings:
```{r}
#| echo: false
loadings^2 |>
  addmargins(margin=1)
```

divide SSloadings by 5 (because 5 observed variables) to get proportion variance
```{r}
#| echo: false
colSums(loadings^2) / 5
```

those two numbers are then cumulatively summed for cumulative variance:
```{r}
#| echo: false
cumsum(colSums(loadings^2) / 5)
```





`r solend()`



`r qbegin("Q3 - MLM [10 marks]", qlabel=F)`

```{r}
#| echo: false
simbasic_rs <- function (seed = NULL, b0 = 0, b1 = 1, z0 = 1, z1 = 1, e = 1) 
{
    if (!is.null(seed)) {
        set.seed(seed)
    }
    N = 200
    n_groups = 20
    g = rep(1:n_groups, e = N/n_groups)
    x = rnorm(N)
    x = rep(1:(N/n_groups),n_groups)
    res = MASS::mvrnorm(n_groups,
                        mu=c(0,0),Sigma=matrix(c(z0,.5,.5,z1),nrow=2))
    re = res[,1][g]
    re_x = res[,2][g]
    b = rbinom(n_groups,1,.5)[g]
    lp = (b0 + re) + (b1 + re_x) * x + -.5*x*b + -b*.57
    y = rnorm(N, mean = lp, sd = e)
    y_bin = rbinom(N, size = 1, prob = plogis(lp))
    data.frame(x, b, g = factor(g), y, y_bin)
}
eseed=round(runif(1,1e3,1e6))
set.seed(485116)
df <- tibble(
  g1 = 1:10,
  b0 = rnorm(10,0,.12),
  b1 = rnorm(10,0,.01),
  data = map2(b0,b1, ~simbasic_rs(b0=..1,b1=..2,z0=2,z1=1.2))
) |> unnest(data)

library(lme4)

df = df |> transmute(
  week = x,
  journal = factor(b,levels=c("0","1"),labels=c("No","Yes")),
  class = g1,
  ppt = g,
  anger = scale(y)[,1]*2.33 + 9.64
)
df = df |>filter(interaction(class,ppt) %in%
              sample(unique(interaction(df$class,df$ppt)),166))

mm = lmerTest::lmer(anger ~ week * journal + 
            (1 + week |class ) + 
            (1 + week |class:ppt), data=df)
#summary(mm)
```

A company that makes "6-minute journals" is undertaking some research to showcase the effectiveness of their product in helping to alleviate unwanted feelings. 
They recruited 166 people signing up to one of 10 "anger management classes" in different cities, and asked them if they would like to have a free journal to help with reflection. 88 participants chose to take a journal, and 78 did not. Each participant filled out weekly assessments of anger levels for 10 weeks. Scores on the anger measure can range from 0 to 15, with changes of 3 being considered 'clinically meaningful'.  

To investigate if having a journal helps to reduce anger levels, the company fit a multilevel model to the data, with anger levels being modelled by week number (0 to 9, with 0 representing the first week participants filled in the anger assessment), whether the journal was used ("no"/"yes", with "no" as the reference level). 

Provide an interpretation of each of:

- the fixed effects **[4 marks]**
- the random effects **[4 marks]**
- the relevance of the findings, considering the context of the study design and researchersâ€™ aims **[2 marks]**

```{r}
#| echo: false
#| out-width: "70%"
knitr::include_graphics("images/mock/mlm.png")
```


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
#| echo: false
res = broom.mixed::tidy(mm) |>
  transmute(
    effect,group,term,est=round(estimate,2)
  )
```



- anger for someone who doesn't journal, at start (in "week 1", or "week 0" is fine here, give benefit of doubt) is `r res[1,4]`
- no significant change over the study period for those who don't journal 
- people to take the journal have lower anger _at the start_ by `r res[3,4]`
- journal group decreases in anger over the study by an additional `r res[4,4]` compared to no-journal group

- both participants and classes vary in starting anger levels and in change in anger over study period
- participants vary (both intercept and slopes of change) much more than classes
- high level of ppt variability relative to fixed slope
- ppts who start more angry decrease less (positive correlation intercepts and slopes)

- take journal = significant reduction in anger
- effect is small - over 10 weeks they only go down by `r (fixef(mm)[2]+fixef(mm)[4])*9`
- difference in two groups at outset suggests two groups are not comparable
- self-selecting journal - maybe all we're doing is splitting up people who do/don't *want* to change


```{r}
#| include: false
broom.mixed::augment(mm) |>
  ggplot(aes(x=week,y=.fitted,group=interaction(class,ppt),
             col=journal))+
  geom_line(alpha=.2)+
  geom_abline(intercept=fixef(mm)[1],slope=fixef(mm)[2],col="red")+
  geom_abline(intercept=fixef(mm)[1]+fixef(mm)[3],slope=fixef(mm)[2]+fixef(mm)[4],col="blue")
```


`r solend()`


`r qbegin("Q3 - hierarchical data structures [4 marks]", qlabel=F)`
Provide example levels for each of the three types of study: Cross-Sectional, Repeated Measures, Longitudinal **[4 marks]**

| level | cross-sectional | repeated measures | longitudinal |
| ----- |---------- |-------------| -----------|
| 2     | ...  |  ... |  ...      |
| 1    | ...| ... | ...  |

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

anything that makes sense here, obvious ones are:

| level | cross-sec | rpt measures | longitudinal |
| ----- |---------- |-------------| -----------|
| 2     |  department |   people |  people |
| 1    | people | experimental items | timepoints |

`r solend()`


