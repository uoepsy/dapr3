[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis for Psychology in R 3 Workbook",
    "section": "",
    "text": "This site contains weekly exercises for the Data Analysis for Psychology in R 3 (DAPR3) course.\nAt the end of each week, solutions (where these are not already available) will be made visible directly beneath each question."
  },
  {
    "objectID": "index.html#about-dapr3",
    "href": "index.html#about-dapr3",
    "title": "Data Analysis for Psychology in R 3 Workbook",
    "section": "About DAPR3",
    "text": "About DAPR3\nData Analysis for Psychology in R 3 (DAPR3) is a course undertaken by 3rd year students in Psychology. DAPR3 builds on the content of DAPR2 and covers more advanced methods that are invaluable for analysing many types of psychological study, preparing students for their dissertations. The course offers students a solid foundation in multilevel modeling, expanding the linear model to analyze “hierarchical data”. Such data often involves observations clustered within higher-level groups, such as trials within participants, timepoints within individuals, or children within schools. In the second half of the course, we delve into data reduction techniques. These methods allow us to effectively summarize multiple correlated variables, either through weighted composites or by positing underlying latent factors. Additionally, students will gain insights into crucial concepts, including measurement error, validity, reliability, and replicability. These concepts are especially essential for researchers in psychology, where surveys or questionnaires are used to conduct studies of underlying constructs that cannot be directly measured."
  },
  {
    "objectID": "index.html#installupdate-r-rstudio",
    "href": "index.html#installupdate-r-rstudio",
    "title": "Data Analysis for Psychology in R 3 Workbook",
    "section": "Install/Update R & RStudio",
    "text": "Install/Update R & RStudio\nMake sure you have installed both R and RStudio on your computer. You may have done this previously for DAPR2, in which case it is probably worth doing some updates.\nPlease make sure to read and follow the instructions below slowly and carefully!!\n\nFor instructions on how to install R and RStudio, click here\nFor instructions on how to update R and RStudio, click here"
  },
  {
    "objectID": "index.html#update-packages",
    "href": "index.html#update-packages",
    "title": "Data Analysis for Psychology in R 3 Workbook",
    "section": "Update Packages",
    "text": "Update Packages\nIt’s worth keeping packages up to date, so it might be worth updating all your packages.\nRunning this code will update all your packages. Just put it into the console (bottom left bit of RStudio):\n\noptions(pkgType = \"binary\")\nupdate.packages(ask = FALSE)"
  },
  {
    "objectID": "index.html#new-packages",
    "href": "index.html#new-packages",
    "title": "Data Analysis for Psychology in R 3 Workbook",
    "section": "New packages!",
    "text": "New packages!\nNow it is probably worth installing a few of the packages that we will be using in DAPR3. There are a few that we will need. For each one, check whether you have it already installed, because there’s not much point wasting time re-installing something you already have!\n\ntidyverse : for organising data\n\nlme4 : for fitting generalised linear mixed effects models\nbroom.mixed : tidying methods for mixed models\neffects : for tabulating and graphing effects in linear models\nlmerTest: for quick p-values from mixed models\nparameters: various inferential methods for mixed models\npsych: for factor analysis\nlavaan: for latent variable models"
  },
  {
    "objectID": "02ex.html",
    "href": "02ex.html",
    "title": "W2 Exercises: Introducing MLM",
    "section": "",
    "text": "These first set of exercises are not “how to do analyses with multilevel models” - they are designed to get you thinking, and help with an understanding of how these models work.\n\n\nQuestion 1\n\n\nRecall the data from last week’s exercises. Instead of looking at the roles A, B and C, we’ll look in more fine grained detail at the seniority. This is mainly so that we have a continuous variable to work with as it makes this illustration easier.\nThe chunk of code below shows a function for plotting that you might not be familiar with - stat_summary(). This takes the data in the plot and “summarises” the Y-axis variable into the mean at every unique value on the x-axis. So below, rather than having a lot of individual data points that represent every employee’s wp (workplace pride), we let stat_summary() compute the mean (the points) plus and minus the standard error (the vertical lines) of all the wp observations at each value of seniority:\n\nlibrary(tidyverse)\njsup &lt;- read_csv(\"https://uoepsy.github.io/data/lmm_jsup.csv\")\n\nggplot(jsup, aes(x = seniority, y = wp, col = role)) +\n  stat_summary(geom=\"pointrange\")\n\n\n\n\n\n\n\n\nBelow is some code that fits a model of the workplace-pride predicted by seniority level. Line 2 then gets the ‘fitted’ values from the model and adds them as a new column to the dataset, called pred_lm. The fitted values are what the model predicts the workplace pride to be for every value of seniority.\nLines 4-7 then plot the data, split up by each department, and adds lines showing the model fitted values.\nRun the code and check that you get a plot. What do you notice about the lines?\n\nlm_mod &lt;- lm(wp ~ seniority, data = jsup)\njsup$pred_lm &lt;- predict(lm_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n\n\n\n\n\n\nSolution\n\n\n\nSolution 1. We should get something like this:\n\nlm_mod &lt;- lm(wp ~ seniority, data = jsup)\njsup$pred_lm &lt;- predict(lm_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n\n\n\n\n\n\n\n\nNote that the lines are exactly the same for each department. This makes total sense, because the model (which is where we’ve got the lines from) completely ignores the department variable!\n\n\n\n\nQuestion 2\n\n\nBelow are 3 more code chunks that all 1) fit a model, then 2) add the fitted values of that model to the plot.\nThe first model is a ‘no-pooling’ approach, similar to what we did in last week’s exercises - adding in dept as a predictor.\nThe second and third are multilevel models. The second fits random intercepts by-department, and the third fits random intercepts and slopes of seniority.\nCopy each chunk and run through the code. Pay attention to how the lines differ.\n\n\nCode\nfe_mod &lt;- lm(wp ~ dept + seniority, data = jsup)\njsup$pred_fe &lt;- predict(fe_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n\n\n\n\nCode\nlibrary(lme4)\nri_mod &lt;- lmer(wp ~ seniority + (1|dept), data = jsup)\njsup$pred_ri &lt;- predict(ri_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n\n\n\n\nCode\nrs_mod &lt;- lmer(wp ~ seniority + (1 + seniority|dept), data = jsup)\njsup$pred_rs &lt;- predict(rs_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 2. With the first model, wp ~ seniority + dept, we are saying the following things:\n\nWe allow the model to estimate an association between workplace pride and seniority. This line is estimated without respect to department, or in other words, for the “average” department.\nWe also allow the model to take that line and shift it up and down for each different department. The slope of the line stays the same. All that’s changing is the vertical position of the line.\n\nLook at UKSA and FSA: the lines are shifted up compared to the others.\nLook at UKSC and OFSTED: the lines are shifted down compared to the others.\n\n\n\nfe_mod &lt;- lm(wp ~ dept + seniority, data = jsup)\njsup$pred_fe &lt;- predict(fe_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n\n\n\n\n\n\n\n\nWith the second model, wp ~ seniority + (1|dept), we are saying the following things:\n\nWe allow the model to estimate an association between workplace pride and seniority.\nWith (1|dept), we allow the model to adjust the intercept of that line, depending on the scores of each department.\n\nIn other words, the wp ~ seniority bit is modelling the average line for all departments, and the (1|dept) bit is saying “now nudge that line up or down so that it fits the data of each individual department better”.\nThis is very similar to the fixed-effects-based model above. The difference is that the nudges up and down are now drawn from a single distribution, so they are all slightly closer to the mean of departments than the changes that the model above made.\nPeople often call these “random intercepts by department”. You may also hear “intercept adjustments by department”.\nIf we look at this model’s summary, we can see how it combines all these individual adjustments into a distribution and give us some summary statistics. This way, we can see how big the adjustments tend to be.\n\n\nSide note: Why use random effects instead of fixed effects, if they do the same thing?\n\nThey don’t really do the same thing: random effects can also include random slopes, which the fixed-effect model cannot do. We’ll see random slopes next.\nFixed effects are generally used for predictors that we have particular hypotheses/predictions about. Random effects are used when we have other sources of non-independence we need to tell the model about.\n\n\nlibrary(lme4)\nri_mod &lt;- lmer(wp ~ seniority + (1|dept), data = jsup)\njsup$pred_ri &lt;- predict(ri_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n\n\n\n\n\n\n\n\nFinally, with the third model, wp ~ seniority + (1 + seniority|dept), we are saying the following things:\n\nWe allow the model to estimate an association between workplace pride and seniority, for departments on average. That’s the wp ~ seniority bit, like before.\nWith (1 + seniority|dept), we allow the model to adjust the intercept of that line AND to adjust the slope of that line for each individual department.\n\nIn other words, the wp ~ seniority bit is modelling the average line for all departments, and the (1 + seniority|dept) bit is saying “now nudge that line up or down AND change how steep it is, so that it fits the data of each individual department better”.\nPeople often call these “random intercepts by department and random slopes over seniority by department”. You may also hear “intercept adjustments by department and adjustments to the slope of seniority by department”.\nIf we look at this model’s summary, we can see how it combines all these individual adjustments into a distribution of intercept adjustments and a distribution of slope adjustments, and give us some summary statistics about both. This way, we can see how big the adjustments tend to be.\n\n\nSo in this next plot, the height of the lines is changing, but additionally, each department’s association between seniority and workplace pride can be different. Some departments (OFQUAL, OFSTED, ORR) have a negative association, some have a flatter association (e.g, FSA, UKSA etc).\n\nrs_mod &lt;- lmer(wp ~ seniority + (1 + seniority|dept), data = jsup)\njsup$pred_rs &lt;- predict(rs_mod)\n\nggplot(jsup, aes(x = seniority)) + \n  geom_point(aes(y = wp), size=1, alpha=.3) +\n  facet_wrap(~dept) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nFrom the previous questions you should have a model called ri_mod.\nBelow is a plot of the fitted values from that model. Rather than having a separate facet for each department as we did above, I have put them all on one plot. The thick black line is the average intercept and slope of the departments lines.\nIdentify the parts of the plot that correspond to A1-4 in the summary output of the model below\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nChoose from these options:\n\nwhere the black line cuts the y axis (at x=0)\n\nthe slope of the black line\n\nthe standard deviation of the distances from all the individual datapoints (employees) to the line for the department in which it works.\n\nthe standard deviation of the distances from all the individual department lines to the black line\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 3. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA1 = the standard deviation of the distances from all the individual department lines to the black line\n\nA2 = the standard deviation of the distances from all the individual datapoints (employees) to the line for the department in which it works.\nA3 = where the black line cuts the y axis\n\nA4 = the slope of the black line\n\n\n\n\n\nOptional Extra\n\n\nBelow is the model equation for the ri_mod model.\nIdentify the part of the equation that represents each of A1-4.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{align}\n\\text{For Employee }j\\text{ from Dept }i & \\\\\n\\text{Level 1 (Employee):}& \\\\\n\\text{wp}_{ij} &= b_{0i} + b_1 \\cdot \\text{seniority}_{ij} + \\epsilon_{ij} \\\\\n\\text{Level 2 (Dept):}& \\\\\nb_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n\\text{Where:}& \\\\\n\\zeta_{0i} &\\sim N(0,\\sigma_{0}) \\\\\n\\varepsilon &\\sim N(0,\\sigma_{e}) \\\\\n\\end{align}\\]\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nChoose from:\n\n\\(\\sigma_{\\varepsilon}\\)\n\n\\(b_{1}\\)\n\n\\(\\sigma_{0}\\)\n\n\\(\\gamma_{00}\\)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 4. \n\nA1 = \\(\\sigma_{0}\\)\n\nA2 = \\(\\sigma_{\\varepsilon}\\)\n\nA3 = \\(\\gamma_{00}\\)\n\nA4 = \\(b_{1}\\)"
  },
  {
    "objectID": "02ex.html#footnotes",
    "href": "02ex.html#footnotes",
    "title": "W2 Exercises: Introducing MLM",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is like taking predict() from the model, and then then grouping by age, and calculating the mean of those predictions. However, we can do this more easily using augment() and then some fancy stat_summary() in ggplot↩︎\nprovided that the confidence intervals and p-values are constructed using the same methods↩︎"
  },
  {
    "objectID": "00tutors.html",
    "href": "00tutors.html",
    "title": "Tutors",
    "section": "",
    "text": "In Week 1, start all labs with a quick:\n“hello. almost all of you are well practiced at DAPR labs now. take a seat, say hello to your colleagues, open Rstudio, and get started on the exercises on Learn.\nwork together with people on your table - explain stuff to one another, troubleshoot together etc.\nfor any questions, we have lovely tutors wandering around, just grab one, or put your hand up etc, and they will be able to help.\nThe groups for the report will not be set until week 3, so for now just sit with whoever you want”"
  },
  {
    "objectID": "00tutors.html#tutor-guidelines",
    "href": "00tutors.html#tutor-guidelines",
    "title": "Tutors",
    "section": "Tutor guidelines",
    "text": "Tutor guidelines\n\ntry to do less:\n\nstanding around chatting\nusing your phone\nsitting with one student for too long\n\ntry to do more:\n\nmake sure every table gets an introduction to a tutor (“hello, i’m X, how are you getting on? etc”)\nmake sure tables don’t get ignored (even if no hands are going up)\nif all is quiet, try actively asking a table 1) where they’re up to in the exercises, 2) if they need any help etc."
  },
  {
    "objectID": "00prereq.html",
    "href": "00prereq.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Install/Update R & RStudio\nMake sure you have installed both R and RStudio on your computer. You may have done this previously for DAPR2, in which case it is probably worth doing some updates.\nPlease make sure to read and follow the instructions below slowly and carefully!!\n\nFor instructions on how to install R and RStudio, click here\nFor instructions on how to update R and RStudio, click here\n\n\n\nUpdate Packages\nIt’s worth keeping packages up to date, so it might be worth updating all your packages.\nRunning this code will update all your packages. Just put it into the console (bottom left bit of RStudio):\n\noptions(pkgType = \"binary\")\nupdate.packages(ask = FALSE)\n\n\n\nNew packages!\nNow it is probably worth installing a few of the packages that we will be using in DAPR3. There are a few that we will need. For each one, check whether you have it already installed, because there’s not much point wasting time re-installing something you already have!\n\ntidyverse : for organising data\n\nlme4 : for fitting generalised linear mixed effects models\nbroom.mixed : tidying methods for mixed models\neffects : for tabulating and graphing effects in linear models\nlmerTest: for quick p-values from mixed models\nparameters: various inferential methods for mixed models\npsych: for factor analysis\nlavaan: for latent variable models"
  },
  {
    "objectID": "01ex.html",
    "href": "01ex.html",
    "title": "W1: Regression Refresher",
    "section": "",
    "text": "Workplace Pride\n\nData: lmm_jsup.csv\nA questionnaire was sent to all UK civil service departments, and the lmm_jsup.csv dataset contains all responses that were received. Some of these departments work as hybrid or ‘virtual’ departments, with a mix of remote and office-based employees. Others are fully office-based.\nThe questionnaire included items asking about how much the respondent believe in the department and how it engages with the community, what it produces, how it operates and how treats its people. A composite measure of ‘workplace-pride’ was constructed for each employee. Employees in the civil service are categorised into 3 different roles: A, B and C. The roles tend to increase in responsibility, with role C being more managerial, and role A having less responsibility. We also have data on the length of time each employee has been in the department (sometimes new employees come straight in at role C, but many of them start in role A and work up over time).\nWe’re interested in whether the different roles are associated with differences in workplace-pride.\nDataset: https://uoepsy.github.io/data/lmm_jsup.csv.\n\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\ndepartment_name\nName of government department\n\n\ndept\nDepartment Acronym\n\n\nvirtual\nWhether the department functions as hybrid department with various employees working remotely (1), or as a fully in-person office (0)\n\n\nrole\nEmployee role (A, B or C)\n\n\nseniority\nEmployees seniority point. These map to roles, such that role A is 0-4, role B is 5-9, role C is 10-14. Higher numbers indicate more seniority\n\n\nemployment_length\nLength of employment in the department (years)\n\n\nwp\nComposite Measure of 'Workplace Pride'\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and provide some descriptive plots and statistics of each individual variable.\n\n\n\n\n\n\nHints\n\n\n\n\n\nDon’t remember how to do descriptives? Think back to previous courses – it’s time for some means, standard deviations, mins and maxes. For categorical variables we can do counts or proportions.\nWe’ve seen various functions such as summary(), and also describe() from the psych package.\nFor continuous variables, histograms are a good first port of call: try hist(). For categorical variables, you could try plotting the outcome of table().\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 1. Here’s the dataset:\n\nlibrary(tidyverse) # for data wrangling\nlibrary(psych) \n\njsup &lt;- read_csv(\"https://uoepsy.github.io/data/lmm_jsup.csv\")\n\nLet’s take just the numeric variables and get some descriptives:\n\njsup |&gt; \n  select(employment_length, wp) |&gt; \n  describe()\n\n                  vars   n mean   sd median trimmed  mad  min  max range  skew\nemployment_length    1 295 12.6 4.28   13.0    12.6 4.45 0.00 30.0  30.0  0.08\nwp                   2 295 25.5 5.27   25.4    25.5 5.93 6.34 38.5  32.1 -0.05\n                  kurtosis   se\nemployment_length     0.38 0.25\nwp                   -0.14 0.31\n\n\nAnd make frequency tables for the categorical ones:\n\ntable(jsup$role)\n\n\n  A   B   C \n109  95  91 \n\n\nI’m going to use dept rather than department_name as the output will be easier to see:\n\ntable(jsup$dept)\n\n\n   ACE    CMA    CPS    FSA    GLD   HMRC    NCA   NS&I  OFGEM OFQUAL OFSTED \n    17     21     13     25     17     16     20     20     15      5     17 \n OFWAT    ORR    SFO   UKSA   UKSC \n    16     17     18     45     13 \n\ntable(jsup$virtual)\n\n\n  0   1 \n175 120 \n\n\n\n\n\n\nQuestion 2\n\n\nAre there differences in ‘workplace-pride’ between people in different roles?\nFirst, plot these two variables together. Based on this plot and your training from DAPR2, try to answer these questions:\n\nIf you fit a model to this data, how would the predictor be coded?\nWhat coefficients would the model estimate?\nWould the sign of the coefficients be positive or negative?\n\nOnce you’ve made a good effort to predict the answers to these questions, fit a model and see if your predictions are borne out. (If your predictions are different from the outcomes, reflect on why the outcomes are the way they are.)\n\n\n\n\n\n\nHints\n\n\n\n\n\ndoes y [continuous variable] differ by x [three groups]?\nlm(y ~ x)?\nBy default, R uses treatment coding (aka dummy coding), and the reference level is the one that comes first in the alphabet.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 2. \n\nmod1 &lt;- lm(wp ~ role, data = jsup)\n\nRather than doing summary(model) - I’m just going to use the broom package to pull out some of the stats in nice tidy dataframes.\nThe glance() function will give us things like the \\(R^2\\) values and \\(F\\)-statistic (basically all the stuff that is at the bottom of the summary()):\n\nlibrary(broom)\nglance(mod1)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.216         0.211  4.68      40.3 3.44e-16     2  -872. 1753. 1768.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nThe tidy() function will give us the coefficients, standard errors, t-statistics and p-values. It’s the same information, just neater!\n\ntidy(mod1)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    28.1      0.448     62.6  3.66e-171\n2 roleB          -2.24     0.657     -3.41 7.33e-  4\n3 roleC          -5.95     0.665     -8.95 4.38e- 17\n\n\nAlternatively, we can get some quick confidence intervals for our coefficients:\n\nconfint(mod1)\n\n            2.5 % 97.5 %\n(Intercept) 27.17 28.933\nroleB       -3.54 -0.949\nroleC       -7.26 -4.638\n\n\nIt looks like roles do differ in their workplace pride. Specifically, compared to people in role A, people who are in roles B and C on average report less pride in the workplace.\n\n\n\n\n\nQuestion 3\n\n\nOne possibility: Something about the roles themselves makes people report differences in workplace pride.\nAnother possibility: People who are newer to the company feel more pride (they’re less jaded), and people in Role A tend to be newer. So something else is at play, but the model above makes it look like it’s about role.\nIn other words, if we were to compare people in each role but hold constant their employment_length, might we see something different?\nMake a plot that shows all these relevant variables. Based on that plot, have a guess at the following questions:\n\nWhat coefficients will be estimated by a model fit to this data?\nWould the sign of the coefficients be positive or negative?\n\nOnce you’ve made a good effort to predict the answers to these questions, fit a model and see. (If your predictions are different from the outcomes, reflect on why the outcomes are the way they are.)\n\n\n\n\n\n\nHints\n\n\n\n\n\nSo we want to adjust for how long people have been part of the company..\nRemember - if we want to estimate the effect of x on y while adjusting for z, we can do lm(y ~ z + x).\nFor the plot - put something on the x, something on the y, and colour it by the other variable.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 3. \n\nmod2 &lt;- lm(wp ~ employment_length + role, data = jsup)\n\ntidy(mod2)\n\n# A tibble: 4 × 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)         36.1      0.709     50.9   6.90e-147\n2 employment_length   -0.834    0.0637   -13.1   4.32e- 31\n3 roleB                0.510    0.563      0.906 3.65e-  1\n4 roleC               -0.704    0.663     -1.06  2.89e-  1\n\n\nNote that, after adjusting for employment length, there are no significant differences in wp between roles B or C compared to A.\nIf we plot the data to show all these variables together, we can kind of see why! Given the pattern of wp against employment_length, the wp for different roles are pretty much where we would expect them to be if role doesn’t make any difference (i.e., if role doesn’t shift your wp up or down).\n\nggplot(jsup, aes(x=employment_length,y=wp,col=role))+\n  geom_point(size=3,alpha=.3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nLet’s take a step back and remember what data we actually have. We’ve got 295 people in our dataset, from 16 departments.\nDepartments may well differ in the general amount of workplace-pride people report. People love to say that they work in the “National Crime Agency”, but other departments might not elicit such pride (*cough* HM Revenue & Customs *cough*). We need to be careful not to mistake department differences as something else (like differences due to the job role).\nMake a couple of plots to look at:\n\nhow many of each role we have from each department\nhow departments differ in their employees’ pride in their workplace\n\n\n\n\n\n\nSolution\n\n\n\nSolution 4. \n\nggplot(jsup, aes(x = role)) + \n  geom_bar()+\n  facet_wrap(~dept)\n\n\n\n\n\n\n\n\nIn this case, it looks like most of the departments have similar numbers of each role, apart from the UKSA (“UK Statistics Authority”), where we’ve got loads more of role A, and very few role C..\nNote also that in the plot below, the UKSA is, on average, full of employees who take a lot of pride in their work. Is this due to the high proportion of people in role A? or is the effect of role we’re seeing more due to differences in departments?\n\nggplot(jsup, aes(x = dept, y = wp)) +\n  geom_boxplot() +\n  scale_x_discrete(labels = label_wrap_gen(35)) + \n  coord_flip()\n\n\n\n\n\n\n\n\nEven if we had perfectly equal numbers of roles in each department, we’re also adjusting for other things such as employment_length, and the extent to which this differs by department can have trickle-on effects on our coefficient of interest (the role coefficients).\n\n\n\n\nQuestion 5\n\n\nAdjusting for both length of employment and department, are there differences in ‘workplace-pride’ between the different roles? Fit a model to find out.\nCan you make a plot of all four of the variables involved in our model?\n\n\n\n\n\n\nHints\n\n\n\n\n\nMaking the plot might take some thinking. We’ve now added dept into the mix, so a nice way might be to use facet_wrap() to make the same plot as the one we did previously, but for each department.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 5. \n\nmod3 &lt;- lm(wp ~ employment_length + dept + role, data = jsup)\ntidy(mod3)\n\n# A tibble: 19 × 5\n   term              estimate std.error statistic   p.value\n   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)        36.4       0.631    57.6    7.17e-156\n 2 employment_length  -0.882     0.0344  -25.7    4.71e- 75\n 3 deptCMA            -3.80      0.649    -5.85   1.39e-  8\n 4 deptCPS            -0.217     0.730    -0.298  7.66e-  1\n 5 deptFSA             4.74      0.625     7.60   4.71e- 13\n 6 deptGLD             0.0582    0.682     0.0853 9.32e-  1\n 7 deptHMRC           -3.79      0.692    -5.47   1.02e-  7\n 8 deptNCA            -3.85      0.655    -5.88   1.18e-  8\n 9 deptNS&I           -0.574     0.654    -0.878  3.81e-  1\n10 deptOFGEM          -0.648     0.705    -0.919  3.59e-  1\n11 deptOFQUAL         -4.94      1.01     -4.89   1.71e-  6\n12 deptOFSTED         -5.88      0.683    -8.61   5.52e- 16\n13 deptOFWAT          -1.21      0.692    -1.75   8.17e-  2\n14 deptORR            -2.85      0.681    -4.18   3.98e-  5\n15 deptSFO            -1.36      0.672    -2.02   4.47e-  2\n16 deptUKSA            4.28      0.576     7.43   1.32e- 12\n17 deptUKSC           -2.31      0.732    -3.16   1.77e-  3\n18 roleB               1.42      0.303     4.68   4.47e-  6\n19 roleC               1.31      0.366     3.59   3.92e-  4\n\n\nIn a way, adding predictors to our model is kind of like splitting up our plots by that predictor to see the patterns. This becomes more and more difficult (/impossible) as we get more variables, but right now we can split the data into all the constituent parts.\n\nggplot(jsup, aes(x = employment_length, y = wp, col = role)) +\n  geom_point(size=3,alpha=.4)+\n  facet_wrap(~dept)\n\n\n\n\n\n\n\n\nThe association between wp and employment_length is clear in all these little sub-plots - there’s a downward trend. The department differences can be seen too: UKSA is generally a bit higher, HMRC and UKSC a bit lower, and so on. By default, the model captures these coefficients as ‘differences from the reference group’, so all these coefficients are in relation to the “ACE” department.\nSeeing the role differences is a bit harder in this plot, but think about what you would expect to see if there were no differences in roles (i.e. imagine if they were all in role A). Take for instance the FSA department, where this is easiest to see - for the people who are in role C, for people of their employment length we would expect their wp to be lower if they were in role A. Likewise for those in role B. Across all these departments, the people in role B and C (green and blue dots respectively) are a bit higher than we would expect. This is what the model coefficients tell us!\n\n\n\n\nQuestion 6\n\n\nNow we’re starting to acknowledge the grouped structure of our data - these people in our dataset are related to one another in that some belong to dept 1, some dept 2, and so on..\nLet’s try to describe our sample in a bit more detail.\n\nhow many participants do we have, and from how many departments?\nhow many participants are there, on average, from each department? what is the minimum and maximum?\nwhat is the average employment length for our participants?\nhow many departments are ‘virtual departments’ vs office-based?\n\nwhat is the overall average reported workplace-pride?\nhow much variation in workplace-pride is due to differences between departments?\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe first lot of these questions can be answered using things like count(), summary(), table(), mean(), min() etc. See 1: Clustered Data #determining-sample-sizes\nFor the last one, we can use the ICC! See 1: Clustered Data #icc\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 6. How many respondents do we have, and from how many departments?\n\nnrow(jsup)\n\n[1] 295\n\nlength(table(jsup$dept))\n\n[1] 16\n\n\nHow many respondents are there, on average, from each dept? What is the minimum and maximum number of people in any one department?\n\njsup |&gt;\n  count(dept) |&gt; \n  summarise(min=min(n),\n            max=max(n),\n            median=median(n)\n  )\n\n# A tibble: 1 × 3\n    min   max median\n  &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n1     5    45     17\n\n\nWhat is the average employment length of respondents?\n\nmean(jsup$employment_length)\n\n[1] 12.6\n\n\nHow many departments are virtual vs office based? This requires a bit more than just table(jsup$virtual), because we are describing a variable at the department level.\n\njsup |&gt; \n  group_by(virtual) |&gt;\n  summarise(\n    ndept = n_distinct(dept)\n  )\n\n# A tibble: 2 × 2\n  virtual ndept\n    &lt;dbl&gt; &lt;int&gt;\n1       0    11\n2       1     5\n\n\nWhat is the overall average ‘workplace-pride’? What is the standard deviation?\n\nmean(jsup$wp)\n\n[1] 25.5\n\nsd(jsup$wp)\n\n[1] 5.27\n\n\nFinally, how much variation in workplace-pride is attributable to department-level differences?\n\nICC::ICCbare(x = dept, y = wp, data = jsup)\n\n[1] 0.439\n\n\n\n\n\n\nQuestion 7\n\n\nWhat if we would like to know whether, when adjusting for differences due to employment length and department and roles, workplace-pride differs between people working in virtual-departments compared to office-based ones?\nCan you add this to the model? What happens?\n\n\n\n\n\nSolution\n\n\n\nSolution 7. Let’s add the virtual predictor to our model. Note that we don’t actually get a coefficient here - it is giving us an NA!\n\nmod4 &lt;- lm(wp ~ employment_length + dept + role + virtual, data = jsup)\n\nsummary(mod4)\n\n\nCall:\nlm(formula = wp ~ employment_length + dept + role + virtual, \n    data = jsup)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.690 -1.404 -0.027  1.178  5.054 \n\nCoefficients: (1 not defined because of singularities)\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        36.3522     0.6310   57.61  &lt; 2e-16 ***\nemployment_length  -0.8817     0.0344  -25.66  &lt; 2e-16 ***\ndeptCMA            -3.7969     0.6490   -5.85  1.4e-08 ***\ndeptCPS            -0.2173     0.7304   -0.30  0.76627    \ndeptFSA             4.7448     0.6245    7.60  4.7e-13 ***\ndeptGLD             0.0582     0.6822    0.09  0.93212    \ndeptHMRC           -3.7859     0.6924   -5.47  1.0e-07 ***\ndeptNCA            -3.8503     0.6549   -5.88  1.2e-08 ***\ndeptNS&I           -0.5737     0.6537   -0.88  0.38095    \ndeptOFGEM          -0.6479     0.7050   -0.92  0.35885    \ndeptOFQUAL         -4.9413     1.0104   -4.89  1.7e-06 ***\ndeptOFSTED         -5.8846     0.6831   -8.61  5.5e-16 ***\ndeptOFWAT          -1.2087     0.6917   -1.75  0.08169 .  \ndeptORR            -2.8452     0.6813   -4.18  4.0e-05 ***\ndeptSFO            -1.3550     0.6719   -2.02  0.04469 *  \ndeptUKSA            4.2820     0.5759    7.43  1.3e-12 ***\ndeptUKSC           -2.3131     0.7325   -3.16  0.00177 ** \nroleB               1.4179     0.3029    4.68  4.5e-06 ***\nroleC               1.3148     0.3663    3.59  0.00039 ***\nvirtual                 NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.98 on 276 degrees of freedom\nMultiple R-squared:  0.867, Adjusted R-squared:  0.859 \nF-statistic:  100 on 18 and 276 DF,  p-value: &lt;2e-16\n\n\nSo what is happening? If we think about it, if we separate out “differences due to departments” then there is nothing left to compare between departments that are virtual vs office based. Adding the between-department predictor of virtual doesn’t explain anything more - the residual sums of squares doesn’t decrease at all:\n\nanova(\n  lm(wp ~ employment_length + dept + role, data = jsup),\n  lm(wp ~ employment_length + dept + role + virtual, data = jsup)\n)\n\nAnalysis of Variance Table\n\nModel 1: wp ~ employment_length + dept + role\nModel 2: wp ~ employment_length + dept + role + virtual\n  Res.Df  RSS Df Sum of Sq F Pr(&gt;F)\n1    276 1084                      \n2    276 1084  0         0         \n\n\nAnother way of thinking about this: knowing the average workplace-pride for the department that someone is in tells me what to expect about that person’s workplace pride. But once I know their department’s average workplace-pride, knowing whether it is ‘virtual’ or ‘office-based’ doesn’t tell me anything new, for the very fact that the virtual/office-based distinction comes from comparing different departments.\nBut we’re not really interested in these departments specifically! What would be nice would be if we can look at the relevant effects of interest (things like role and virtual), but then just think of the department differences as just some sort of random variation. So we want to think of departments in a similar way to how we think of our individual employees - they vary randomly around what we expect - only they’re at a different level of observation."
  },
  {
    "objectID": "03ex.html",
    "href": "03ex.html",
    "title": "W3 Exercises: Nested and Crossed Structures",
    "section": "",
    "text": "Data: gadeduc.csv\nThis is synthetic data from a randomised controlled trial, in which 30 therapists randomly assigned patients (each therapist saw between 2 and 28 patients) to a control or treatment group, and monitored their scores over time on a measure of generalised anxiety disorder (GAD7 - a 7 item questionnaire with 5 point likert scales).\nThe control group of patients received standard sessions offered by the therapists. For the treatment group, 10 mins of each sessions was replaced with a specific psychoeducational component, and patients were given relevant tasks to complete between each session. All patients had monthly therapy sessions. Generalised Anxiety Disorder was assessed at baseline and then every visit over 4 months of sessions (5 assessments in total).\nThe data are available at https://uoepsy.github.io/data/lmm_gadeduc.csv\nYou can find a data dictionary below:\n\n\n\n\nTable 1: Data Dictionary: lmm_gadeduc.csv\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\npatient\nA patient code in which the labels take the form &lt;Therapist initials&gt;_&lt;group&gt;_&lt;patient number&gt;.\n\n\nvisit_0\nScore on the GAD7 at baseline\n\n\nvisit_1\nGAD7 at 1 month assessment\n\n\nvisit_2\nGAD7 at 2 month assessment\n\n\nvisit_3\nGAD7 at 3 month assessment\n\n\nvisit_4\nGAD7 at 4 month assessment\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nUh-oh… these data aren’t in the same shape as the other datasets we’ve been giving you..\nCan you get it into a format that is ready for modelling?\n\n\n\n\n\n\nTipHints\n\n\n\n\n\n\nIt’s wide, and we want it long.\n\nOnce it’s long. “visit_0”, “visit_1”,.. needs to become the numbers 0, 1, …\nOne variable (patient) contains lots of information that we want to separate out. There’s a handy function in the tidyverse called separate(), check out the help docs!\n\n\n\n\n\n\n\n\n\n1 - reshaping\n\n\n\nSolution 1. Here’s the data. We have one row per patient, but we have multiple observations for each patient across the columns..\n\ngeduc = read_csv(\"https://uoepsy.github.io/data/lmm_gadeduc.csv\")\nhead(geduc)\n\n# A tibble: 6 × 6\n  patient      visit_0 visit_1 visit_2 visit_3 visit_4\n  &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 VC_Control_1      24      24      26      29      28\n2 VC_Control_2      24      26      28      29      30\n3 VC_Control_3      25      29      27      29      30\n4 VC_Control_4      24      25      25      26      26\n5 VC_Control_5      28      28      27      29      28\n6 VC_Control_6      26      28      25      27      28\n\n\nWe can make it long by taking the all the columns from visit_0 to visit_4 (that is, from the second column 2 to the last column last_col()) and shoving their values into one variable called GAD, and keeping the name of the column they come from as another variable called visit:\n\ngeduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\")\n\n# A tibble: 2,410 × 3\n   patient      visit     GAD\n   &lt;chr&gt;        &lt;chr&gt;   &lt;dbl&gt;\n 1 VC_Control_1 visit_0    24\n 2 VC_Control_1 visit_1    24\n 3 VC_Control_1 visit_2    26\n 4 VC_Control_1 visit_3    29\n 5 VC_Control_1 visit_4    28\n 6 VC_Control_2 visit_0    24\n 7 VC_Control_2 visit_1    26\n 8 VC_Control_2 visit_2    28\n 9 VC_Control_2 visit_3    29\n10 VC_Control_2 visit_4    30\n# ℹ 2,400 more rows\n\n\nThis is step 1 of our data wrangling. In the next step, we’ll pipe the result of pivot_longer() into mutate().\nIn general, building up and running your data wrangling pipeline step by step, the way we’re illustrating here, is a good way to make sure each step of your code really is doing what you think it’s doing.\n\n\n\n\n\n2 - time is numeric\n\n\n\nSolution 2. Now we know how to get our data long, we need to sort out our time variable (visit) and make it into numbers.\nWe can replace all occurrences of the string \"visit_\" in our data with nothingness \"\", and then convert what remains—the visit number—to numeric.\n\ngeduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |&gt;\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) \n\n# A tibble: 2,410 × 3\n   patient      visit   GAD\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 VC_Control_1     0    24\n 2 VC_Control_1     1    24\n 3 VC_Control_1     2    26\n 4 VC_Control_1     3    29\n 5 VC_Control_1     4    28\n 6 VC_Control_2     0    24\n 7 VC_Control_2     1    26\n 8 VC_Control_2     2    28\n 9 VC_Control_2     3    29\n10 VC_Control_2     4    30\n# ℹ 2,400 more rows\n\n\n\n\n\n\n\n3 - splitting up the patient variable\n\n\n\nSolution 3. Finally, we need to sort out the patient variable. It contains 3 bits of information that we will want to have separated out. It has the therapist (their initials), then the group (treatment or control), and then the patient number. These are all separated by an underscore “_“.\nThe separate() function takes a column and separates it into several things (as many things as we give it), splitting them by some user defined separator such as an underscore:\n\ngeduc_long &lt;- geduc |&gt; \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |&gt;\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) |&gt;\n  separate(patient, into=c(\"therapist\",\"group\",\"patient\"), sep=\"_\")\n\nAnd we’re ready to go!\n\ngeduc_long\n\n# A tibble: 2,410 × 5\n   therapist group   patient visit   GAD\n   &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 VC        Control 1           0    24\n 2 VC        Control 1           1    24\n 3 VC        Control 1           2    26\n 4 VC        Control 1           3    29\n 5 VC        Control 1           4    28\n 6 VC        Control 2           0    24\n 7 VC        Control 2           1    26\n 8 VC        Control 2           2    28\n 9 VC        Control 2           3    29\n10 VC        Control 2           4    30\n# ℹ 2,400 more rows\n\n\n\n\n\n\nQuestion 2\n\n\nVisualise the data. Does it look like the treatment had an effect over time? Does it look like the treatment worked when used by every therapist?\n\n\n\n\n\n\nTipHints\n\n\n\n\n\n\nremember, stat_summary() is very useful for aggregating data inside a plot.\n\n\n\n\n\n\n\n\nHere’s the overall picture. The average score on the GAD7 at each visit gets more and more different between the two groups. The treatment looks effective..\n\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\")\n\n\n\n\n\n\n\n\nLet’s split this up by therapist, so we can see the averages across each therapist’s set of patients.\nThere’s clear variability between therapists in how well the treatment worked. For instance, the therapists EU and OD don’t seem to have much difference between their groups of patients.\n\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\") +\n  facet_wrap(~therapist)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nFit a model to test if the psychoeducational treatment is associated with greater improvement in anxiety over time.\nStep 1: Choose the appropriate fixed effects.\nStep 2: Think about the grouping structure in the data.\nStep 3: Choose the appropriate random effects.\nNote that the patient variable does not uniquely specify the individual patients. That is, patient “1” from therapist “AO” is a different person from patient “1” from therapist “BJ”.\n\n\n\n\nWe want to know if how anxiety (GAD) changes over time (visit) is different between treatment and control (group).\nHopefully this should hopefully come as no surprise1 - it’s an interaction!\n\nlmer(GAD ~ visit * group + ...\n       ...\n     data = geduc_long)\n\n\n\n\n\nWe have multiple observations for each of the 482 patients, and those patients are nested within 30 therapists.\nNote that in our data, the patient variable does not uniquely specify the individual patients. i.e. patient “1” from therapist “AO” is a different person from patient “1” from therapist “BJ”. To correctly group the observations into different patients (and not ‘patient numbers’), we need to have therapist:patient.\nSo we capture therapist-level differences in ( ... | therapist) and the patients-within-therapist-level differences in ( ... | therapist:patient):\n\nlmer(GAD ~ visit * group + ...\n       ( ... | therapist) + \n       ( ... | therapist:patient),\n     data = geduc_long)\n\n\n\n\n\nNote that each patient can change differently in their anxiety levels over time - i.e. the slope of visit could vary by participant.\nLikewise, some therapists could have patients who change differently from patients from another therapist, so visit|therapist can be included.\nEach patient is in one of the two groups - they’re either treatment or control. So we can’t say that “differences in anxiety due to treatment varies between patients”, because for any one patient the “difference in anxiety due to treatment” is not defined in our study design.\nHowever, therapists see multiple different patients, some of which are in the treatment group, and some of which are in the control group. So the treatment effect could be different for different therapists!\n\nmod1 &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|therapist:patient),\n             geduc_long)\n\n\n\n\n\nThe question asked whether the psychoeducational treatment (in the variable group) is associated with greater improvement in anxiety (GAD) over time (visit).\nLet’s take a look at the model summary to find out.\n\nsummary(mod1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: GAD ~ visit * group + (1 + visit * group | therapist) + (1 +  \n    visit | therapist:patient)\n   Data: geduc_long\n\nREML criterion at convergence: 8696\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7051 -0.5341  0.0147  0.5412  2.9954 \n\nRandom effects:\n Groups            Name                 Variance Std.Dev. Corr             \n therapist:patient (Intercept)          1.448    1.203                     \n                   visit                1.014    1.007    0.07             \n therapist         (Intercept)          1.602    1.266                     \n                   visit                0.211    0.459    -0.09            \n                   groupTreatment       0.082    0.286    -0.13  0.02      \n                   visit:groupTreatment 0.154    0.392    -0.14 -0.20 -0.49\n Residual                               0.706    0.840                     \nNumber of obs: 2410, groups:  therapist:patient, 482; therapist, 30\n\nFixed effects:\n                     Estimate Std. Error t value\n(Intercept)           25.1910     0.2528   99.64\nvisit                 -0.5780     0.1120   -5.16\ngroupTreatment         0.0313     0.1377    0.23\nvisit:groupTreatment  -0.8375     0.1233   -6.79\n\nCorrelation of Fixed Effects:\n            (Intr) visit  grpTrt\nvisit       -0.073              \ngroupTrtmnt -0.278  0.029       \nvst:grpTrtm -0.067 -0.442 -0.160\n\n\nThe question focuses on the fixed effects, so let’s look at those coefficients and their t-values.\n\nvisit: We see a negative association between visit and GAD: the more therapy visits you have, the less your anxiety. The t-value here is more extreme than 2 (which is, as a rule of thumb, approximately the t-value that represents the boundary of the 95% CI). So we likely have a significant negative association between time and anxiety. If this association is significant, that means we can reject the null hypothesis that there’s no change in anxiety over time.\ngroupTreatment: We see a very small positive association between group and GAD, but the error is much bigger than the estimate itself, and consequently, the t-value is also pretty close to 0. I doubt we can reject the null hypothesis that, on average, there’s no difference between the treatment and control groups.\nvisit:groupTreatment: We see a negative coefficient for the interaction between visit and groupTreatment, accompanied by a fairly extreme t-value. We likely have a significant negative interaction. This means that we can reject the null hypothesis that there’s no difference between groups as time goes on. And the negative coefficient means that, as visits increase, the GAD of the treatment group decreases more than the GAD of the control group does. (Note: Interactions are REALLY hard to interpret just based on model coefficients. The best way to interpret them is to look at plots of the data.)\n\nTo see whether our guesses about significance based on the t-values were on the right track, we can re-fit the model using lmerTest.\n\nmod1_test &lt;- lmerTest::lmer(\n  GAD ~ visit*group + \n    (1+visit*group|therapist) +\n    (1+visit|therapist:patient),\n  geduc_long\n)\nsummary(mod1_test)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: GAD ~ visit * group + (1 + visit * group | therapist) + (1 +  \n    visit | therapist:patient)\n   Data: geduc_long\n\nREML criterion at convergence: 8696\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7051 -0.5341  0.0147  0.5412  2.9954 \n\nRandom effects:\n Groups            Name                 Variance Std.Dev. Corr             \n therapist:patient (Intercept)          1.448    1.203                     \n                   visit                1.014    1.007    0.07             \n therapist         (Intercept)          1.602    1.266                     \n                   visit                0.211    0.459    -0.09            \n                   groupTreatment       0.082    0.286    -0.13  0.02      \n                   visit:groupTreatment 0.154    0.392    -0.14 -0.20 -0.49\n Residual                               0.706    0.840                     \nNumber of obs: 2410, groups:  therapist:patient, 482; therapist, 30\n\nFixed effects:\n                     Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)           25.1910     0.2528 28.7248   99.64  &lt; 2e-16 ***\nvisit                 -0.5780     0.1120 25.7009   -5.16  2.3e-05 ***\ngroupTreatment         0.0313     0.1377 21.4408    0.23     0.82    \nvisit:groupTreatment  -0.8375     0.1233 18.8874   -6.79  1.8e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) visit  grpTrt\nvisit       -0.073              \ngroupTrtmnt -0.278  0.029       \nvst:grpTrtm -0.067 -0.442 -0.160\n\n\nYes, the effects deemed “significant” based on Satterthwaite’s method are the ones we expected.\nSo yes, it looks like the treatment group does improve more over time, compared to the control group, taking into account all the variability introduced by individual patients and therapists.\n\n\n\n\nQuestion 4\n\n\nFor each of the models below, what is wrong with the random effect structure?\n\nmodelA &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|patient),\n             geduc_long)\n\n\nmodelB &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist/patient),\n             geduc_long)\n\n\n\n\n\n\nmodelA &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|patient),\n             geduc_long)\n\nThe patient variable doesn’t capture the different patients within therapists, so this actually fits crossed random effects and treats all data where patient==1 as from the same group (even if this includes several different patients’ worth of data from different therapists!)\n\nmodelB &lt;- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist/patient),\n             geduc_long)\n\nUsing the / here means we have the same random slopes fitted for therapists and for patients-within-therapists.\nConcretely, (1+visit*group|therapist/patient) is shorthand for (1 + visit*group | therapist) (which is fine) + (1 + visit*group | patient:therapist) (which is not fine, because we don’t have data for every participant for both groups.\nIn other words, the effect of group can’t vary by patient, so this doesn’t work, hence why we need to split them up into (...|therapist)+(...|therapist:patient).\n\n\n\n\nQuestion 5\n\n\nLet’s suppose that I don’t want the psychoeducation treatment, I just want the standard therapy sessions that the ‘Control’ group received. Which therapist should I go to?\n\n\n\n\n\n\nTipHints\n\n\n\n\n\nranef() and dotplot.ranef.mer() might help here!\nYou can read about ranef in Chapter 2 #making-model-predictions.\n\n\n\n\n\n\n\nThe three best therapists to go to are SZ, AO, or IT.\nWhy?\n\nWe said we don’t care about getting the treatment, so we can ignore the parameters groupTreatment and visit:groupTreatment.\n(Intercept) doesn’t tell us about the effect that each therapist has over time, just how good they’re estimated to be at visit 0.\nvisit is the parameter that tells us about how anxiety changes over time. And because lower GAD is better, we want scores to decrease over time.\n\nSo we can look at which therapists have the most negative slope estimated for visit:\n\nranef(mod1)$therapist |&gt;\n  arrange(visit)\n\n   (Intercept)   visit groupTreatment visit:groupTreatment\nSZ      0.9726 -0.6888        0.24172             -0.22323\nAO      1.1432 -0.6187        0.12352             -0.36515\nIT     -1.1505 -0.5899       -0.07238              0.31514\nYS     -0.4871 -0.5669       -0.06642             -0.03349\nGW      1.2185 -0.4012        0.08385             -0.22424\nYF      1.6864 -0.3063       -0.21452              0.27618\nBT      0.3180 -0.2006        0.02731             -0.27356\nCX     -2.0325 -0.1830        0.07968              0.04229\nYE     -0.0752 -0.1196       -0.11644              0.37766\nBJ      0.4484 -0.1189        0.13249             -0.17044\nOD      0.3721 -0.1095       -0.00822              0.01031\nLI      1.2294 -0.1060        0.05093             -0.30194\nWB     -1.3593 -0.0762        0.12765             -0.22974\nXA     -0.5062 -0.0623       -0.03208              0.28862\nOI     -0.2767 -0.0181       -0.21774              0.33791\nTV     -1.9303  0.0405       -0.04087              0.11939\nDF     -0.4995  0.0754        0.12759              0.03542\nDJ     -1.4707  0.0854        0.06195              0.02053\nPM      0.2754  0.1224       -0.02787              0.04960\nMV      0.9641  0.1595       -0.01265              0.15929\nOE     -0.2371  0.1874        0.13167              0.01460\nRW      0.3232  0.2004        0.10072             -0.31093\nLO      1.8762  0.2146       -0.05420              0.00338\nMY     -0.5791  0.2166       -0.02696              0.08902\nKD      0.4017  0.2669        0.01441             -0.36769\nEU     -1.3717  0.3149       -0.03290              0.26114\nKI      2.7614  0.3276       -0.29723              0.17496\nCS     -1.2525  0.4871       -0.00584             -0.00782\nXQ     -1.3365  0.5703       -0.27320              0.33072\nVC      0.5743  0.8970        0.19604             -0.39791\n\n\nDouble check using the plot:\n\ndotplot.ranef.mer(ranef(mod1))$therapist\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nRecreate this plot.\nThe faint lines represent the model estimated lines for each patient. The points and ranges represent our fixed effect estimates and their uncertainty.\nMake sure you’re plotting model estimates, not the raw data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipHints\n\n\n\n\n\n\nyou can get the patient-specific lines using augment() from the broom.mixed package, and the fixed effects estimates using effect() from the effects package.\nremember that the “patient” column doesn’t group observations into unique patients.\nremember you can pull multiple datasets into ggplot:\n\n\nggplot(data = dataset1, aes(x=x,y=y)) + \n  geom_point() + # points from dataset1\n  geom_line(data = dataset2) # lines from dataset2\n\n\nsee more in Chapter 2 #visualising-models\n\n\n\n\n\n\n\n\n\n1 - the relevant parts\n\n\n\nSolution 4. The effects package will give us the fixed effect estimates:\n\nlibrary(effects)\nlibrary(broom.mixed)\neffplot &lt;- effect(\"visit*group\",mod1) |&gt;\n  as.data.frame()\n\nWe want to get the fitted values for each patient. We can get fitted values using augment(). But the patient variable doesn’t capture the unique patients, it just captures their numbers (which aren’t unique to each therapist).\nSo we can create a new column called upatient which pastes together the therapists initials and the patient numbers\n\naugment(mod1) |&gt; \n  mutate(\n    upatient = paste0(therapist,patient),\n    .after = patient # place the column next to the patient col\n  )\n\n# A tibble: 2,410 × 17\n     GAD visit group   therapist patient upatient .fitted .resid  .hat .cooksd\n   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt;     &lt;fct&gt;   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1    24     0 Control VC        1       VC1         24.2 -0.198 0.454 0.0210 \n 2    24     1 Control VC        1       VC1         25.3 -1.28  0.239 0.239  \n 3    26     2 Control VC        1       VC1         26.4 -0.360 0.186 0.0128 \n 4    29     3 Control VC        1       VC1         27.4  1.56  0.294 0.508  \n 5    28     4 Control VC        1       VC1         28.5 -0.522 0.563 0.284  \n 6    24     0 Control VC        2       VC2         24.8 -0.843 0.454 0.383  \n 7    26     1 Control VC        2       VC2         26.2 -0.171 0.239 0.00426\n 8    28     2 Control VC        2       VC2         27.5  0.502 0.186 0.0250 \n 9    29     3 Control VC        2       VC2         28.8  0.174 0.294 0.00633\n10    30     4 Control VC        2       VC2         30.2 -0.153 0.563 0.0246 \n# ℹ 2,400 more rows\n# ℹ 7 more variables: .fixed &lt;dbl&gt;, .mu &lt;dbl&gt;, .offset &lt;dbl&gt;, .sqrtXwt &lt;dbl&gt;,\n#   .sqrtrwt &lt;dbl&gt;, .weights &lt;dbl&gt;, .wtres &lt;dbl&gt;\n\n\n\n\n\n\n\n2 - constructing the plot\n\n\n\nSolution 5. \n\nlibrary(effects)\nlibrary(broom.mixed)\neffplot &lt;- effect(\"visit*group\",mod1) |&gt;\n  as.data.frame()\n\naugment(mod1) |&gt; \n  mutate(\n    upatient = paste0(therapist,patient),\n    .after = patient # place the column next to the patient col\n  ) |&gt;\n  ggplot(aes(x=visit,y=.fitted,col=group))+\n  stat_summary(geom=\"line\", aes(group=upatient,col=group), alpha=.1)+\n  geom_pointrange(data=effplot, aes(y=fit,ymin=lower,ymax=upper,col=group))+\n  labs(x=\"- Month -\",y=\"GAD7\")"
  },
  {
    "objectID": "03ex.html#footnotes",
    "href": "03ex.html#footnotes",
    "title": "W3 Exercises: Nested and Crossed Structures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nif it does, head back to where we learned about interactions in the single level regressions lm(). It’s just the same here.↩︎"
  }
]