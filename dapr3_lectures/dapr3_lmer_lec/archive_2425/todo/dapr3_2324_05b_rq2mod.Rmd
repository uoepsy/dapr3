---
title: "<b>Multi-level Model Research Questions</b>"
subtitle: "Data Analysis for Psychology in R 3"
author: "Josiah King"
institute: "Department of Psychology<br/>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: jk_libs/libs
    css: 
      - xaringan-themer.css
      - jk_libs/tweaks.css
    nature:
      beforeInit: "jk_libs/macros.js"
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(patchwork)
library(lme4)
library(lmeresampler)
library(effects)
options(htmltools.dir.version = FALSE)
options(digits=4,scipen=2)
options(knitr.table.format="html")

xaringanExtra::use_share_again()
xaringanExtra::use_xaringan_extra(c("tile_view","animate_css","tachyons"))
xaringanExtra::use_extra_styles(
  mute_unhighlighted_code = FALSE
)

knitr::opts_chunk$set(
  dev = "svg",
  warning = FALSE,
  message = FALSE,
  cache = FALSE
)
theme_set(
    theme_minimal() + 
    theme(text = element_text(size=20))
)
source("jk_source/jk_presfuncs.R")

library(xaringanthemer)
style_mono_accent(
  base_color = "#88B04B", # DAPR3 
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro"),
  code_font_size = "0.7rem",
  extra_css = list(".scroll-output" = list("height"="90%","overflow-y"="scroll"))
)
```

class: inverse, center, middle

<h2>Part 1: Model Specification</h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Model fitting</h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Interpretation & Inference</h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Reporting</h2>

---
class: center, middle
# How do we get from research questions and study design to model specification?  

---
# Study 
In 2010 A US state's commissioner for education was faced with growing community concern about rising levels of adolescent antisocial behaviours. 

After a series of focus groups, the commissioner approved the trialing of an intervention in which yearly Parent Management Training (PMT) group sessions were offered to the parents of a cohort of students entering 10 different high schools. Every year, the parents were asked to fill out an informant-based version of the Aggressive Behaviour Scale (ABS), measuring verbal and physical abuse, socially inappropriate behavior, and resisting care. Where possible, the same parents were followed up throughout the child's progression through high school. Alongside this, parents from a cohort of students entering 10 further high schools in the state were recruited to also complete the same informant-based ABS, but were not offered the PMT group sessions.  
The commissioner has two main questions: **Does the presentation of aggressive behaviours increase as children enter the secondary school system? If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?**  

The data is available at https://uoepsy.github.io/data/abs_intervention.csv 

???
- READ SLIDE DESCRIPTION
- 2 Research Qs here

---
# Data

```{r echo=FALSE}
absint<-read_csv("https://uoepsy.github.io/data/abs_intervention.csv")

tibble(
  variable = names(absint),
  description = c("Name of school","Participant number","Age of participant (in years) at observation","Informant-based Aggressive Behaviour Scale (ABS) score (range 0 to 100)","Whether or not the school was part of the intervention group in which Parent Management Training (PMT) group sessions were offered to the parents")
) %>% knitr::kable()
```

```{r}
absint<-read_csv("https://uoepsy.github.io/data/abs_intervention.csv") %>% mutate(interv=factor(interv))
head(absint)
```

???
- let's take a look at the data we've been given
- here are variables
- here's the top of the data 
  - describe SLIDE data


---
# Outcome and Fixed Effects  

.br2.f4.gray.bg-white[
(g)lmer(**outcome** ~ fixed effects + (random effects | grouping structure), family = error distribution)
]

.pull-left[
- What are we interested in explaining/predicting?  

]

.pull-right[
> Does the presentation of aggressive behaviours increase as children enter the secondary school system? If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

]

???
- so we need to translate this to a model
- first.. focus on the main aims

- here are our questions. 
- QUESTION anyone want to shout out what our outcome is?  
- WRITE BOARD


---
# Outcome and Fixed Effects  

.br2.f4.gray.bg-white[
(g)lmer(**outcome** ~ fixed effects + (random effects | grouping structure), family = error distribution)
]

.pull-left[
- What are we interested in explaining/predicting?  

]

.pull-right[
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

]

???
- so we need to translate this to a model
- first.. focus on the main aims

- here are our questions. 
- QUESTION anyone want to shout out what our outcome is?  
- WRITE BOARD


---
count:false
# Outcome and Fixed Effects  

.br2.f4.gray.bg-white[
**(g)lmer**(outcome ~ fixed effects + (random effects | grouping structure), **family = error distribution**)
]

.pull-left[

- What are we interested in explaining/predicting?  

  - How is this measured?

]
.pull-right[
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

```{r echo=FALSE, fig.width=3,fig.height=2}
ggplot(absint, aes(x=ABS))+
  geom_histogram()
```


]

???
- it's a continuous measure here, so we're in the lmer world
- we're not using logistic models or anything

---
count:false
# Outcome and Fixed Effects  

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ **fixed effects** + (random effects | grouping structure), family = error distribution)
]

.pull-left[

- What are we interested in explaining/predicting?  

  - How is this measured?

- What variables are we interested in explaining this by?  

]
.pull-right[
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

```{r echo=FALSE}
head(absint, 4L) %>% mutate(interv=as.numeric(as.character(interv)), ABS = round(ABS,1)) %>% rbind("...")  %>% as_tibble() %>% kable()
```

]

???
- QUESTION what are we suggesting might explain levels of aggressive behaviour?  
  - age
  - intervention
  - interaction

- WRITE BOARD

- side note: are these things (age, intervention) measured at different levels? 
  - intervention is a school thing
  - age is a thing that changes every observation
    - e.g. we see ppt1 at age 12, 13, etc.
- what's known as a cross-level interaction. multilevel models are ideal for this kind of question
  


---
# Within & Between Effects

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ **fixed effects** + (random effects | grouping structure), family = error distribution)
]

.pull-left[

- Are our questions about the effects of our predictors specifically in reference to _group means_ of predictors?  

  - "the effect of being higher on $x$ *__for a__* group"  
  
  - "the effect of a group being *__on average__* higher on $x$" 

]
.pull-right[
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

]

???
- we should think about whether we are going to want to do any group mean centering here.  
- BOARD POINT

- our only predictor that could be mean centered is age, intervention is a factor
- WRITE POSSIBLE BOARD
- there are two things to think about
  - how data is collected
    - each child is measured at age 12, 13, 14.. etc up to the end of school
    - so each child has the same average age. so group mean centering doesn't do anything
  - but even if we did have ppt1 from age 9-13, and ppt2 from 11-15, etc. 
    - do we want to separate out "being older than you're average age" and "being on average a bit older"? 
    - probably not. these sort of things make more sense when the predictors to be some feature of the person that makes them distinct. e.g. i'm nervous, you're not. contrast that with i'm old, you're not. but you will be one day. 
- no need to mean center here

---
# The Grouping Structure  

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (random effects | grouping structure), family = error distribution)
]

.pull-left[
- In what different ways can we group our data?   

]
???
- okay, now we start thinking about groups.  
- first off.. how can we group our data? 

--
.pull-right[
```{r echo=FALSE}
head(absint, 4L) %>% mutate(interv=as.numeric(as.character(interv)), ABS = round(ABS,1)) %>% rbind("...")  %>% as_tibble() %>% kable()
```
]

???
- shout out and tell me all the ways in which i can group this data
  - basically looking for anything that isn't continuous
  - school
  - child/ppt
  - intervention


---
# The Grouping Structure  

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (random effects | grouping structure), family = error distribution)
]

.pull-left[
- In what different ways can we group our data?   

- Of the different ways we can group our data, which groupings are of specific inferential interest?  

- Of the different ways we can group our data, which groupings do we think of as a random sample from a general population of groups? 

]
.pull-right[
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

```{r echo=FALSE}
head(absint, 4L) %>% mutate(interv=as.numeric(as.character(interv)), ABS = round(ABS,1)) %>% rbind("...")  %>% as_tibble() %>% kable()
```
]
???
- okay. there are two further questions we should now ask.
- NEXT 

---
count:false
# The Grouping Structure  

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ **fixed effects** + (random effects | grouping structure), family = error distribution)
]

.pull-left[
- In what different ways can we group our data?   

- **Of the different ways we can group our data, which groupings are of specific inferential interest?**  

- Of the different ways we can group our data, which groupings do we think of as a random sample from a general population of groups? 

]
.pull-right[
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

```{r echo=FALSE}
head(absint, 4L) %>% mutate(interv=as.numeric(as.character(interv)), ABS = round(ABS,1)) %>% rbind("...")  %>% as_tibble() %>% kable()
```
]
???
- READ
- when should my variable be a "fixed effect" and when should it be the "cluster"?  
- 1. which of those groupings are of specific interest?
  - interv.
  - we can't have it both here (fixef) and here (grouping). 
- we have Interv in our fixed effects, so that's all we need to do with interv right now.  
- but this specific inferential interest doesn't apply to schools, or children  
  


---
count:false
# The Grouping Structure  

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (random effects | **grouping structure**), family = error distribution)
]

.pull-left[
- In what different ways can we group our data?   

- Of the different ways we can group our data, which groupings are of specific inferential interest?  

- **Of the different ways we can group our data, which groupings do we think of as a random sample from a general population of groups?** 

]
.pull-right[
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

```{r echo=FALSE}
head(absint, 4L) %>% mutate(interv=as.numeric(as.character(interv)), ABS = round(ABS,1)) %>% rbind("...")  %>% as_tibble() %>% kable()
```
]
???
- READ
- so, we've got our remaining groupings (schools, children)
- can we think of either of these as a random sample from a broader population of groups?  
  - yes. we could have done the same study with different children
  - we could have done the same study with different schools
- so schools and children are going to go into this grouping structure bit

---
# The Grouping Structure  

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (random effects | **grouping structure**), family = error distribution)
]

.pull-left[
- In what different ways can we group our data?   

- Of the different ways we can group our data, which groupings are of specific inferential interest?  

- Of the different ways we can group our data, which groupings do we think of as a random sample from a general population of groups? 

  - Is there more than one grouping of this sort, and if so, are these groupings nested? Are the labels unique?  
  
  - For each level, how many groups have we sampled?  
]
???
- now we just need to figure out _how_ they go in there.. 
- so yet further questions to ask ourselves
- READ

--
.pull-right[

```{r}
nrow(absint)
absint %>% 
  mutate(schoolppt = interaction(schoolid,ppt)) %>%
  summarise(across(everything(), n_distinct))
```

]
???
- so this is a little trick i sometimes use.
- we have 1528 rows in our data
- here i'm just making a variable that is both the schoolid and the ppt id. so the values would be "blue river high school ppt 1", and "blue river high school ppt 2" etc. they would be unique.
- then, summarising across every variable, we can check how many different distinct values we have.
- we have 20 schools
- 14 distinct "ppt" labels
- now this already tells us that the ppt labels aren't unique - because there are less children than schools. 
- ignore age, abs, and interv, we know about those. 
- we can see we have 191 "schoolppt" values. so that's actually how many children we have in total



---
count: false
# The Grouping Structure  

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (random effects | **grouping structure**), family = error distribution)
]

.pull-left[
- In what different ways can we group our data?   

- Of the different ways we can group our data, which groupings are of specific inferential interest?  

- Of the different ways we can group our data, which groupings do we think of as a random sample from a general population of groups? 

  - Is there more than one grouping of this sort, and if so, are these groupings nested? Are the labels unique?  
  
  - For each level, how many groups have we sampled?  
]
.pull-right[

```{r}
table(absint$schoolid, absint$ppt)
```

]
???
- another way to quickly see this is to make a table of schools vs ppts. 
- we can see the labels for ppt along the top. 
- and the labels for schools down the left
- but we know that the cells of this table should reflect _different_ children
- WRITE BOARD


---
# Random Intercepts and Slopes

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (**random effects** | grouping structure), family = error distribution)
]

.pull-left[

- Which of our fixed effects can vary for our random groups?  

  - "does a single group have multiple _distinct_ values for $x$?"  
  
  - "for the data from only one of our groups, can we estimate $y \sim x$?"

]
???
- okay, we're getting there. the next thing is to try and work out _what_ we can allow to vary by our groupings  
- what's up for grabs? anything in the fixed effects
- good way to start thinking:
- READ


--
.pull-right[
All the data:
```{r echo=FALSE, fig.asp=.4}
library(patchwork)
absint %>% 
  ggplot(.,aes(x=ABS))+
  geom_histogram() + 
absint %>% 
  ggplot(.,aes(x=age, y=ABS))+
  geom_point() + 
absint %>% mutate(interv=factor(interv)) %>% 
  ggplot(.,aes(x=interv, y=ABS))+
  geom_point() + 
  scale_x_discrete(drop=FALSE)
```
Data from School == "Central High":
```{r echo=FALSE, fig.asp=.4}
library(patchwork)
absint %>% filter(schoolid == "Central High") %>% 
  ggplot(.,aes(x=ABS))+
  geom_histogram() + 
absint %>% filter(schoolid == "Central High") %>%
  ggplot(.,aes(x=age, y=ABS))+
  geom_point() + 
absint %>% mutate(interv=factor(interv)) %>% filter(schoolid == "Central High") %>%
  ggplot(.,aes(x=interv, y=ABS))+
  geom_point() + 
  scale_x_discrete(drop=FALSE)
```

]

???
- great way to see, is to plot it
- so here's all the data on top,
- here's aggression as a histogram, and aggression over age, and aggression over the intervention y/n
- below, here it is for a single school. 
- i can fit the line for age
- so, if i plot a different schools' data, i might get a different line. in that way, the assocation between aggression and age _could_ vary by schools
- can i say the same thing for the intervention?
  - no

---
# Random Intercepts and Slopes

.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (**random effects** | grouping structure), family = error distribution)
]

.pull-left[

- Which of our fixed effects can vary for our random groups?  

  - "does a single group have multiple values for $x$?"  
  
  - "for the data from only one of our groups, can we estimate $y \sim x$?"

]
.pull-right[
All the data:
```{r echo=FALSE, fig.asp=.4}
library(patchwork)
absint %>% 
  ggplot(.,aes(x=ABS))+
  geom_histogram() + 
absint %>% 
  ggplot(.,aes(x=age, y=ABS))+
  geom_point() + 
absint %>% mutate(interv=factor(interv)) %>% 
  ggplot(.,aes(x=interv, y=ABS))+
  geom_point() + 
  scale_x_discrete(drop=FALSE)
```
Data from School == "Central High", Participant == "1":
```{r echo=FALSE, fig.asp=.4}
library(patchwork)
absint %>% filter(schoolid == "Central High", ppt == 1) %>% 
  ggplot(.,aes(x=ABS))+
  geom_histogram() +
absint %>% filter(schoolid == "Central High", ppt == 1) %>%
  ggplot(.,aes(x=age, y=ABS))+
  geom_point() + 
absint %>% mutate(interv=factor(interv)) %>% filter(schoolid == "Central High", ppt == 1) %>%
  ggplot(.,aes(x=interv, y=ABS))+
  geom_point() + 
  scale_x_discrete(drop=FALSE)
```

]

???
- what about for a single child?
- age yes, intervention no 


---
# Our model  
.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (random effects | grouping structure), family = error distribution)
]
--
.br2.f4.green.bg-white[
&nbsp; &nbsp; &nbsp; lmer(ABS &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ~ age * interv + (1 + age &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | &nbsp; &nbsp; schoolid&nbsp; /&nbsp; ppt&nbsp; &nbsp; )
]

---
count: false
# Our model  
.br2.f4.gray.bg-white[
(g)lmer(outcome ~ fixed effects + (random effects | grouping structure), family = error distribution)
]
.br2.f4.green.bg-white[
&nbsp; &nbsp; &nbsp; lmer(ABS &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ~ ageC * interv + (1 + ageC &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | &nbsp; &nbsp; schoolid&nbsp; /&nbsp; ppt&nbsp; &nbsp; )
]

```{r echo=FALSE}
absint <- absint %>% mutate(ageC = age - 12)
head(absint, 4L) %>% mutate(ABS = round(ABS,1), ageC = age-12) %>% mutate(interv=as.character(interv)) %>% rbind("...")  %>% as_tibble() %>% kable()
```

```{r eval=FALSE,echo=FALSE}
absmod <- lmer(ABS ~ ageC * interv + (1 + ageC | schoolid/ppt), data = absint,
     control = lmerControl(optimizer="bobyqa"))

lmer(ABS ~ age * interv + (1 + age | schoolid/ppt) , data = absint %>% mutate(age=age-12),
     control = lmerControl(optimizer="bobyqa")) -> d
VarCorr(d)
broom.mixed::augment(d) %>%
  ggplot(.,aes(x=age,y=.fitted,group=interaction(schoolid,ppt)))+
  geom_line()


lmer(ABS ~ age * interv + (1 + age | schoolid/ppt) , data = absint,
     control = lmerControl(optimizer="bobyqa")) -> d2
VarCorr(d2)
broom.mixed::augment(d2) %>%
  ggplot(.,aes(x=age,y=.fitted,group=interaction(schoolid,ppt)))+
  geom_line()


absint %>% count(interv,schoolid,ppt) %>%
  mutate(age = 0) %>%
  mutate(.fitted = predict(d2, newdata=.)) %>% 
  bind_rows(broom.mixed::augment(d2), .) %>%
  ggplot(.,aes(x=age,y=.fitted,group=interaction(schoolid,ppt)))+
  geom_line()
```




---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: Model Specification</h2>
<h2>Part 2: Model fitting</h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Interpretation & Inference</h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Reporting</h2>

---
# Model issues

- Check for convergence issues & singular fits. 
```{r}
absmod <- lmer(ABS ~ ageC * interv + (1 + ageC | schoolid/ppt), data = absint,
     control = lmerControl(optimizer="bobyqa"), REML = TRUE)
```
```{r echo=FALSE}
absmod@optinfo$message
```

???
simplify if necessary 

--

- Check assumptions have been met

--

.pull-left[
```{r echo=FALSE, fig.height=4}
plot(absmod,
     type = c("p"), main = "fitted vs residuals")
```
]
.pull-right[
```{r echo=FALSE, fig.height=4}
plot(absmod, 
     form = sqrt(abs(resid(.))) ~ fitted(.),
     type = c("p"), main="scale-location")
```
]

???
we also want to look at how the spread changes over the fitted values of the model



---
# Model issues

- Convergence issues. 
```{r}
absmod <- lmer(ABS ~ ageC * interv + (1 + ageC | schoolid/ppt), data = absint,
     control = lmerControl(optimizer="bobyqa"), REML = TRUE)
```
```{r echo=FALSE}
absmod@optinfo$message
```

- Check assumptions have been met

```{r echo=FALSE, fig.width=16, fig.height=5}
par(mfrow=c(1,5))
qqnorm(resid(absmod), main = "level one residuals")
qqline(resid(absmod))
qqnorm(ranef(absmod)$schoolid$`(Intercept)`, main="School level random intercepts")
qqline(ranef(absmod)$schoolid$`(Intercept)`)
qqnorm(ranef(absmod)$schoolid$ageC, main="School level random slopes of age")
qqline(ranef(absmod)$schoolid$ageC)
qqnorm(ranef(absmod)$ppt$`(Intercept)`, main="Child level random intercepts")
qqline(ranef(absmod)$ppt$`(Intercept)`)
qqnorm(ranef(absmod)$ppt$ageC, main="Child level random slopes of age")
qqline(ranef(absmod)$ppt$ageC)
par(mfrow=c(1,1))
```

???
- we saw how this involves checking normality of not just residuals, but of random effects - because we think of htem as level 2 residuals
- respecify model, transform, or attempt to address in some way.  

---
# Model issues

- Convergence issues. 
```{r}
absmod <- lmer(ABS ~ ageC * interv + (1 + ageC | schoolid/ppt), data = absint,
     control = lmerControl(optimizer="bobyqa"), REML = TRUE)
```
```{r echo=FALSE}
absmod@optinfo$message
```

- Check assumptions have been met

- Do tests if you want, but beware. Multilevel data tends to have bigger $n$, and these tests are overly sensitive.  
Personally, I prefer plots. 
```{r echo=FALSE, fig.width=16, fig.height=5}
normst <- list(shapiro.test(resid(absmod)),
shapiro.test(ranef(absmod)$schoolid$`(Intercept)`),
shapiro.test(ranef(absmod)$schoolid$ageC),
shapiro.test(ranef(absmod)$ppt$`(Intercept)`),
shapiro.test(ranef(absmod)$ppt$ageC)
)
map_chr(normst, ~paste0(.$method," ",.$data.name," W=",round(.$statistic,2),", p=",round(.$p.value,2)))
```

???
- we can, if we want, conduct statistical tests on the residuals, such as checking normality. 
- however, the visual is usually fine


---
# Model issues

- Convergence issues. 
```{r}
absmod <- lmer(ABS ~ ageC * interv + (1 + ageC | schoolid/ppt), data = absint,
     control = lmerControl(optimizer="bobyqa"), REML = TRUE)
```
```{r echo=FALSE}
absmod@optinfo$message
```

- Check assumptions have been met

```{r echo=FALSE, fig.width=16, fig.height=5}
library(HLMdiag)
library(patchwork)
l1 <- hlm_influence(absmod, level=1)
l2 <- hlm_influence(absmod, level="ppt:schoolid")
l3 <- hlm_influence(absmod, level="schoolid")
(dotplot_diag(l1$cooksd) + labs(title="Cook's D: Observations")) + 
(dotplot_diag(l2$cooksd) + labs(title="Cook's D: Children"))+ 
(dotplot_diag(l3$cooksd) + labs(title="Cook's D: School")) 
```

???
- we also want to check for influence! 
- and this is influence at every level, so at the observation
   - so one child just goes wildly aggressive at age 16, but then goes back to normal 
   - at the child - so this would be one child who's trajectory of aggression is just not in keeping with the rest. so.. they're just exponentially getting more and more aggressive with age or something
   - and at the school level. this would be like having a school that is just full of aggressive children, or really calm children. 


---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: Model Specification</h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Model fitting</h2>
<h2>Part 3: Interpretation & Inference</h2>
<h2 style="text-align: left;opacity:0.3;">Part 4: Reporting</h2>


---
# Fixed effects

.pull-left[
```{r}
fixef(absmod)
```
]
.pull-right[
MAP IT TO THE PLOT!!!!
]

---
count: false
# Fixed effects

.pull-left[
```{r}
fixef(absmod)
```
]
.pull-right[
```{r fig.asp=.8}
library(sjPlot)
plot_model(absmod, type="int")
```
]


---
# Inference

.pull-left[
## Tests

- Model comparison

- Parameter estimates


]
.pull-right[
## Methods

- df approximations
  `parameters::model_parameterS(model, ci_method="kr")`
  `pbkrtest::KRmodcomp(model2,model1)`
- Likelihood Ratio Tests  
  `anova(model1, model2, ...)`
- Bootstrap
  - parametric bootstrap
    `pbkrtest::PBmodcomp()` and `confint(method="boot")`
  - case bootstrap
    `lmeresampler::bootstrap(model, type = "case", resample = c(....))`
]

???
- once we're happy with the model
- we need to conduct some inferences, so we can talk about the probability of getting estimates as extreme as the ones we __have__ got, if there were no effect in the true population.  

- we have options of how we do this:
  - compare models
  - conduct tests on parameter estimates

- note. should say, model comparisons don't mean we ignore the parameter estimates - e.g. the fixed effects.
  - we test how their inclusion changes model fit,
  - but the fixed effect estimate itself is still of interest - it describes the relationship.  
  
- and we have a whole load of options on how we do either. 
- main thing to remember, which i think i've repeated lots of times, LRT needs big samples at all levels, bootstrapping needs stable models (and takes time to compute).  

---
# Inference

> **Research Questions**  
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?

--

```{r}
fixef(absmod)
```


---
# Inference

e.g.:  
```{r}
parameters::model_parameters(absmod, ci_method="kr")
```

```{r echo=FALSE, eval=FALSE}
library(lmeresampler)
absmodBS <- bootstrap(absmod, .f=fixef, type = "case", 
                      B = 2000, resample = c(FALSE,TRUE,FALSE))
confint(absmodBS, type="perc")

load("absmodBS.RData")
confint(absmodBS, type="perc")
```

---
# Random effects  

Use them to add context to results  

--

- e.g. they can give a descriptive answer to "should we expect *all* children get more aggressive in secondary school?" 

```{r fig.asp=.6, echo=FALSE}
ggplot(data = data.frame(x = c(-6, 6)), aes(x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 1.67, sd = 2.22)) + ylab("") +
  scale_y_continuous(breaks = NULL) + theme_blank() +
  geom_vline(xintercept = 1.67,lty="dotted")+
  labs(x = "slope of ABS ~ age", title="SD ppt:schoolid ageC = 2.22") -> p1

ggplot(data = data.frame(x = c(-6, 6)), aes(x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 1.67, sd = 0.65)) + ylab("") +
  scale_y_continuous(breaks = NULL) + theme_blank() +
  geom_vline(xintercept = 1.67,lty="dotted")+
  labs(x = "slope of ABS ~ age", title = "SD ppt:schoolid ageC = 0.65") -> p2

p1 | p2

```


---
# Random effects  

Use them to add context to results  


- e.g. they can give a descriptive answer to "should we expect *all* children get more aggressive in secondary school?" 

```{r fig.asp=.6, echo=FALSE}
plotline = MASS::mvrnorm(n=250, mu=fixef(absmod)[1:2],Sigma=VarCorr(absmod)[[1]]) %>%
  as_tibble() |> mutate(interv="0")
plotline2 = MASS::mvrnorm(n=250, mu=c(sum(fixef(absmod)[c(1,3)]),sum(fixef(absmod)[c(2,4)])),Sigma=VarCorr(absmod)[[1]]) %>%
  as_tibble() |> mutate(interv="1")

ggplot(absint, aes(x=ageC, y=ABS))+
  geom_point(col=NA)+
  guides(col="none")+
  geom_abline(data=plotline, aes(intercept=`(Intercept)`,slope=ageC,col=interv),alpha=.1)+
  geom_abline(intercept=fixef(absmod)[1],slope=fixef(absmod)[2])+
  geom_abline(data=plotline2, aes(intercept=`(Intercept)`,slope=ageC,col=interv),alpha=.1)+ 
  geom_abline(intercept=sum(fixef(absmod)[c(1,3)]),slope=sum(fixef(absmod)[c(2,4)]))-> p1


ss = VarCorr(absmod)[[1]]-4.5
ss = pracma::nthroot(ss,n=5)
plotline = MASS::mvrnorm(n=250, mu=fixef(absmod)[1:2],Sigma=ss) %>%
  as_tibble() |> mutate(interv="0")
plotline2 = MASS::mvrnorm(n=250, mu=c(sum(fixef(absmod)[c(1,3)]),sum(fixef(absmod)[c(2,4)])),Sigma=ss) %>%
  as_tibble() |> mutate(interv="1")

ggplot(absint, aes(x=ageC, y=ABS))+
  geom_point(col=NA)+
  guides(col="none")+
  geom_abline(data=plotline, aes(intercept=`(Intercept)`,slope=ageC,col=interv),alpha=.1)+
  geom_abline(intercept=fixef(absmod)[1],slope=fixef(absmod)[2])+
  geom_abline(data=plotline2, aes(intercept=`(Intercept)`,slope=ageC,col=interv),alpha=.1)+ 
  geom_abline(intercept=sum(fixef(absmod)[c(1,3)]),slope=sum(fixef(absmod)[c(2,4)]))-> p2

p1 | p2
```




---
class: inverse, center, middle

<h2 style="text-align: left;opacity:0.3;">Part 1: Model Specification</h2>
<h2 style="text-align: left;opacity:0.3;">Part 2: Model fitting</h2>
<h2 style="text-align: left;opacity:0.3;">Part 3: Interpretation & Inference</h2>
<h2>Part 4: Reporting</h2>

---
# Reporting the analysis process

- Data cleaning outlier/data removal, transformations _prior to_ analysis.  

- Unplanned transformations and data removal which are carried out in order to meet assumptions.  

--

- Specify all fixed effects (explanatory variables & covariates).  
Link them to explicitly stated research questions/hypotheses. 

- Explicitly state the hierarchical structure of the data and of the model.  
Specify random effects according to the sampling units (schools/children etc) with which they interact. 

--

- Planned structure of random effects to be fitted   

- Procedure to be used to decide on final random effect structure.  


--

- State clearly the relevant test/comparison/parameter estimate of interest.  
Link to explicitly stated research questions/hypotheses.  

  - Method you plan to use to conduct inference (e.g. LRT, kr, bootstrap)
  - Any model comparisons should be clearly stated so that the reader understands the structure of *both* models being compared.  



---
# Reporting results

.pull-left[
- Software packages and versions used to fit the model(s), along with the estimation method (ML/REML) and optimiser used.   

- If proposed model failed to converge:  
  - steps leading to final converging model.  
  - final model structure  

]

--

.pull-right[
For final model:  

- all parameter estimates for fixed effects.  

    - coefficients
    - standard errors and/or confidence intervals
    - associated test statistics, df and p-values (if used)  
    
{{content}} 
]
 
--

- random effects  

  - standard deviation and/or variance for each random effect
  - correlations/covariances if modelled   
  - residual variance/standard deviation
  
<!-- {{content}} -->

<!-- -- -->

<!-- - some measure of model fit (marginal/conditional $R^2$) -->



---
# Reporting: text and tables

.pull-left[
Tables help a lot!  

{{content}}
]

--

But *they are not a substitute for interpretation*  

- Key parameters of interest should also be included in-text, with interpretation.  


---
count: false
# Reporting: text and tables

.pull-left[
Tables help a lot!  

But *they are not a substitute for interpretation*  

- Key parameters of interest should also be included in-text, with interpretation.  

```{r eval=FALSE}
library(sjPlot)
tab_model(absmod, show.p = FALSE, df.method="kr")
```

]

.pull-right[
<small>
```{r echo=FALSE}
library(sjPlot)
tab_model(absmod, show.p = FALSE, df.method="kr")
```
</small>
]


---
# Visualising the model(s)  

- Think about your questions  

.pull-left[
```{r echo=FALSE, fig.asp=.8}
ggplot()+
  labs(y="Outcome",x="Some explanatory variable of interest")
```
]
.pull-right[
> 1. Does the presentation of aggressive behaviours increase as children enter the secondary school system? 
> 2. If so, is there any evidence for the effectiveness of Parent Management Training (PMT) group sessions in curbing the rise of aggressive behaviors during a child's transition into the secondary school system?
]

---
# Visualising the model(s)

.pull-left[
There's always `sjPlot::plot_model()`!
```{r echo=FALSE, fig.asp=.8}
sjPlot::plot_model(absmod, type="int")
```
]
--
.pull-right[
But plotting manually gives you more control:
```{r echo=FALSE, fig.asp=.8}
library(effects)
#effs <- as.data.frame(effect("ageC:interv", absmod))
load("jk_source/effs.RData")

facetlabs <- c(
  `0` = "No Intervention",
  `1` = "Parent Management\nTraining"
)

broom.mixed::augment(absmod) %>%
ggplot(., aes(x=ageC+12,
              col=interv))+
  geom_point(aes(y=ABS), alpha=.1) +
  geom_line(aes(y=ABS,group=interaction(schoolid,ppt)), alpha=.2) +
  scale_color_manual("Intervention",values=c("#BF1932","#88B04B"),
                     labels=c("None","PMT"))+
  guides(fill="none",col="none")+
  labs(y="ABS", x="")+
  facet_grid(~interv, labeller = as_labeller(facetlabs)) -> p1

broom.mixed::augment(absmod) %>%
ggplot(., aes(x=ageC+12,
              col=interv))+
  geom_line(aes(y=.fitted,group=interaction(schoolid,ppt)), alpha=.1) +
  geom_line(data=effs, aes(y=fit), lwd=1)+
  geom_ribbon(data=effs, aes(ymax=upper,ymin=lower, fill=interv), alpha=.2)+
  scale_color_manual("Intervention",values=c("#BF1932","#88B04B"),
                     labels=c("None","PMT"))+
  scale_fill_manual("Intervention",values=c("#BF1932","#88B04B"),
                    labels=c("None","PMT"))+
  labs(y="Model fit", x="- Age (years) -")+
  guides(fill="none",col="none") -> p2

p1 / p2
```
]

---
class: inverse, center, middle, animated, rotateInDownLeft

# End
## Thanks for listening!

