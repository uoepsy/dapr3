{
  "hash": "1c474dcb13b3d73abf8eba99c9b4c3e5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exploratory Factor Analysis 1\"\neditor_options: \n  chunk_output_type: console\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n# Course Overview\n\n\n<table style=\"border: 1px solid black;>\n  <tr style=\"padding: 0 1em 0 1em;\">\n    <td rowspan=\"5\" style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1;text-align:center;vertical-align: middle\">\n        <b>multilevel modelling<br>working with group structured data</b></td>\n    <td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1\">\n        regression refresher</td>\n  </tr>\n  <tr><td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1\">\n        introducing multilevel models</td></tr>\n  <tr><td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1\">\n        more complex groupings</td></tr>\n  <tr><td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1\">\n        centering, assumptions, and diagnostics</td></tr>\n  <tr><td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1\">\n        recap</td></tr>\n\n  <tr style=\"padding: 0 1em 0 1em;\">\n    <td rowspan=\"5\" style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1;text-align:center;vertical-align: middle\">\n        <b>factor analysis<br>working with multi-item measures</b></td>\n    <td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1\">\n        what is a psychometric test?</td>\n  </tr>\n  <tr><td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1\">\n        using composite scores to simplify data (PCA)</td></tr>\n  <tr><td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:1\">\n        <b>uncovering underlying constructs (EFA)</b></td></tr>\n  <tr><td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4\">\n        more EFA</td></tr>\n  <tr><td style=\"border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4\">\n        recap</td></tr>\n</table>\n\n\n# This week {transition=\"slide\"}\n\n-   Introduction to EFA\n-   EFA vs PCA\n-   Estimation & Number of factors problem\n-   Factor rotation\n-   Example and interpretation\n\n# Introduction to EFA\n\n*Real friends don't let friends do PCA.* (W. Revelle, 25 October 2020)\n\n## Questions to ask before you start\n\n::: columns\n::: {.column width=\"50%\"}\n-   Why are your variables correlated?\n    -   Agnostic/don't care\n    -   Believe there *are* underlying \"causes\" of these correlations\n-   What are your goals?\n    -   Just reduce the number of variables\n    -   Reduce your variables and learn about/model their underlying\n        (latent) causes\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-3-1.png){width=529}\n:::\n:::\n\n:::\n:::\n\n## Questions to ask before you start\n\n::: columns\n::: {.column width=\"50%\"}\n-   Why are your variables correlated?\n    -   Agnostic/don't care\n    -   **Believe there *are* underlying \"causes\" of these\n        correlations**\n-   What are your goals?\n    -   Just reduce the number of variables\n    -   **Reduce your variables and learn about/model their\n        underlying(latent) causes**\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-4-1.png){width=529}\n:::\n:::\n\n:::\n:::\n\n## Latent variables\n\n::: columns\n::: {.column width=\"50%\"}\n-   One of many features that distinguish factor analysis and principal\n    components analysis\n\n-   Key concept of psychometrics (factor analysis is a part)\n\n-   Theorized common cause (e.g., cognitive ability) of responses to a\n    set of variables\n\n    -   Explain correlations between measured variables\n    -   Held to be true\n    -   No direct test of this theory\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-5-1.png){width=529}\n:::\n:::\n\n:::\n:::\n\n## An example\n\n::: columns\n::: {.column width=\"50%\"}\nSuppose we conduct a survey, and we ask 1000 people to respond to the\nfollowing 10 questions which measure different aspects aggression.\n\nRead the items, how do you think they might group?\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"vxpromvvyz\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#vxpromvvyz table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#vxpromvvyz thead, #vxpromvvyz tbody, #vxpromvvyz tfoot, #vxpromvvyz tr, #vxpromvvyz td, #vxpromvvyz th {\n  border-style: none;\n}\n\n#vxpromvvyz p {\n  margin: 0;\n  padding: 0;\n}\n\n#vxpromvvyz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#vxpromvvyz .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#vxpromvvyz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#vxpromvvyz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#vxpromvvyz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#vxpromvvyz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#vxpromvvyz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#vxpromvvyz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#vxpromvvyz .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#vxpromvvyz .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#vxpromvvyz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#vxpromvvyz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#vxpromvvyz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#vxpromvvyz .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#vxpromvvyz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vxpromvvyz .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#vxpromvvyz .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#vxpromvvyz .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#vxpromvvyz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vxpromvvyz .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#vxpromvvyz .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vxpromvvyz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#vxpromvvyz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vxpromvvyz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vxpromvvyz .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vxpromvvyz .gt_left {\n  text-align: left;\n}\n\n#vxpromvvyz .gt_center {\n  text-align: center;\n}\n\n#vxpromvvyz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#vxpromvvyz .gt_font_normal {\n  font-weight: normal;\n}\n\n#vxpromvvyz .gt_font_bold {\n  font-weight: bold;\n}\n\n#vxpromvvyz .gt_font_italic {\n  font-style: italic;\n}\n\n#vxpromvvyz .gt_super {\n  font-size: 65%;\n}\n\n#vxpromvvyz .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#vxpromvvyz .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#vxpromvvyz .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#vxpromvvyz .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#vxpromvvyz .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#vxpromvvyz .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#vxpromvvyz .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"item\">item</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"wording\">wording</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">1</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I hit someone</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">2</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I kicked someone </td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">3</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I shoved someone </td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">4</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I battered someone </td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">5</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I physically hurt someone on purpose </td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">6</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I deliberately insulted someone</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">7</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I swore at someone</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">8</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I threatened to hurt someone</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">9</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I called someone a nasty name to their face</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">10</td>\n<td headers=\"wording\" class=\"gt_row gt_left\">I shouted mean things at someone</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n:::\n:::\n\n## Our running example\n\n\n\n\n\n-   What do you see if you look at the item correlations?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(cor(agg.items),2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       item1 item2 item3 item4 item5 item6 item7 item8 item9 item10\nitem1   1.00  0.50  0.41  0.42  0.53  0.11  0.15  0.11  0.13   0.06\nitem2   0.50  1.00  0.50  0.47  0.62  0.13  0.18  0.13  0.12   0.08\nitem3   0.41  0.50  1.00  0.39  0.52  0.08  0.11  0.07  0.12   0.05\nitem4   0.42  0.47  0.39  1.00  0.51  0.11  0.12  0.10  0.12   0.06\nitem5   0.53  0.62  0.52  0.51  1.00  0.12  0.16  0.09  0.11   0.02\nitem6   0.11  0.13  0.08  0.11  0.12  1.00  0.56  0.55  0.39   0.45\nitem7   0.15  0.18  0.11  0.12  0.16  0.56  1.00  0.74  0.54   0.58\nitem8   0.11  0.13  0.07  0.10  0.09  0.55  0.74  1.00  0.54   0.59\nitem9   0.13  0.12  0.12  0.12  0.11  0.39  0.54  0.54  1.00   0.45\nitem10  0.06  0.08  0.05  0.06  0.02  0.45  0.58  0.59  0.45   1.00\n```\n\n\n:::\n:::\n\n\n## Practical Steps\n\nSo how do we move from data and correlations to a factor analysis?\n\n1.  Check the appropriateness of the data and decide of the appropriate\n    estimator.\n2.  Decide which methods to use to select a number of factors.\n3.  Decide conceptually whether to apply rotation and how to do so.\n4.  Decide on the criteria to assess and modify your solution.\n5.  Run the analysis.\n6.  Evaluate the solution (apply 4)\n7.  Select a final solution and interpret the model, labeling the\n    factors.\n8.  Report your results.\n\n::: aside\nWe will be working through these steps in the next 2 weeks.\n:::\n\n## What does an EFA look like?\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\nagg_res <- fa(agg.items, nfactors = 2, fm = \"ml\", rotate = \"oblimin\")\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nagg_res\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFactor Analysis using method =  ml\nCall: fa(r = agg.items, nfactors = 2, rotate = \"oblimin\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n         ML1   ML2   h2   u2 com\nitem1   0.02  0.65 0.43 0.57   1\nitem2   0.02  0.76 0.59 0.41   1\nitem3  -0.01  0.64 0.41 0.59   1\nitem4   0.01  0.62 0.38 0.62   1\nitem5  -0.02  0.82 0.67 0.33   1\nitem6   0.64  0.03 0.42 0.58   1\nitem7   0.85  0.04 0.74 0.26   1\nitem8   0.87 -0.03 0.74 0.26   1\nitem9   0.62  0.04 0.40 0.60   1\nitem10  0.70 -0.07 0.47 0.53   1\n\n                       ML1  ML2\nSS loadings           2.77 2.48\nProportion Var        0.28 0.25\nCumulative Var        0.28 0.52\nProportion Explained  0.53 0.47\nCumulative Proportion 0.53 1.00\n\n With factor correlations of \n     ML1  ML2\nML1 1.00 0.19\nML2 0.19 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  45  with the objective function =  3.93 with Chi Square =  3912\ndf of  the model are 26  and the objective function was  0.02 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.01 \n\nThe harmonic n.obs is  1000 with the empirical chi square  9.7  with prob <  1 \nThe total n.obs was  1000  with Likelihood Chi Square =  19.7  with prob <  0.81 \n\nTucker Lewis Index of factoring reliability =  1\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.016\nBIC =  -160\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.94 0.92\nMultiple R square of scores with factors          0.89 0.85\nMinimum correlation of possible factor scores     0.78 0.69\n```\n\n\n:::\n:::\n\n:::\n:::\n\n## Key parts of the output\n\n-   **Factor loading's**, like PCA loading's, show the relationship of\n    each measured variable to each factor.\n\n    -   They range between -1.00 and 1.00\n    -   Larger absolute values = stronger relationship between measured\n        variable and factor\n\n-   We interpret our factor models by the pattern and size of these\n    loading's.\n\n    -   **Primary loading's**: refer to the factor on which a measured\n        variable has it's highest loading\n    -   **Cross-loading's**: refer to all other factor loading's for a\n        given measured variable\n\n-   Square of the factor loading's tells us how much item variance is\n    explained ( `h2` ), and how much isn't ( `u2`)\n\n-   **Factor correlations** : When estimated, tell us how closely\n    factors relate (see rotation)\n\n-   `SS Loading` and proportion of variance information is interpreted\n    as we discussed for PCA.\n\n# EFA vs PCA\n\n## PCA versus EFA: How are they different?\n\n::: columns\n::: {.column width=\"50%\"}\n**PCA**\n\n-   The observed measures $(x_{1}, x_{2}, x_{3})$ are independent\n    variables\n-   The component $(\\mathbf{z})$ is the dependent variable\n-   Explains as much variance in the measures $(x_{1}, x_{2}, x_{3})$ as\n    possible\n-   Components are determinate\n:::\n\n::: {.column width=\"50%\"}\n**EFA**\n\n-   The observed measures $(y_{1}, y_{2}, y_{3})$ are dependent\n    variables\n    -   The factor $(\\xi)$, is the independent variable\n    -   Models the relationships between variables\n        $(r_{y_{1},y_{2}},r_{y_{1},y_{3}}, r_{y_{2},y_{3}})$\n    -   Factors are *in*determinate\n:::\n:::\n\n## Modeling the data\n\n-   What does it mean to model the data?\n\n-   EFA tries to explain these patterns of correlations\n\n    -   If, for a set of items (here 3), the model (factor or $\\xi$) is\n        good, it will explain their interrelationships\n    -   Read the dots $(\\cdot)$ as \"given\" or \"controlling for\"\n\n$$\n\\begin{equation}\n\\rho(y_{1},y_{2}\\cdot\\xi)=corr(e_{1},e_{2})=0 \\\\\n\\rho(y_{1},y_{3}\\cdot\\xi)=corr(e_{1},e_{3})=0 \\\\\n\\rho(y_{2},y_{3}\\cdot\\xi)=corr(e_{2},e_{3})=0 \\\\\n\\end{equation}\n$$\n\n## Modeling the data\n\n-   In order to model these correlations, EFA looks to distinguish\n    between the true and unique item variance\n\n$$\n\\begin{equation}\nvar(total) = var(common) + var(specific) + var(error)\n\\end{equation}\n$$\n\n-   True variance\n    -   Variance common to an item and at least one other item\n    -   Variance specific to an item that is not shared with any other\n        items\n-   Unique variance\n    -   Variance specific to an item that is not shared with any other\n        items\n    -   Error variance\n\n## The general factor model equation\n\n$$\\mathbf{\\Sigma}=\\mathbf{\\Lambda}\\mathbf{\\Phi}\\mathbf{\\Lambda'}+\\mathbf{\\Psi}$$\n\n-   $\\mathbf{\\Sigma}$: A $p \\times p$ observed covariance matrix (from\n    data)\n\n-   $\\mathbf{\\Lambda}$: A $p \\times m$ matrix of factor loading's\n    (relates the $m$ factors to the $p$ items)\n\n-   $\\mathbf{\\Phi}$: An $m \\times m$ matrix of correlations between\n    factors (\"goes away\" with orthogonal factors)\n\n-   $\\mathbf{\\Psi}$: A diagonal matrix with $p$ elements indicating\n    unique (error) variance for each item\n\n## Assumptions\n\n-   As EFA is a model, just like linear models and other statistical\n    tools, it has some assumptions:\n\n    1.  The residuals/error terms $(e)$ should be uncorrelated (it's a\n        diagonal matrix, remember!)\n    2.  The residuals/errors should not correlate with factor\n    3.  Relationships between items and factors should be linear,\n        although there are models that can account for nonlinear\n        relationships\n\n# Suitability of data, Estimation & Number of factors problem\n\n## Data suitability\n\n-   This boils down to is the data correlated.\n    -   So the initial check is to look to see if there are moderate\n        correlations (roughly \\> .20)\n-   We can take this a step further and calculate the squared multiple\n    correlation (SMC).\n    -   SMC are multiple correlations of each item regressed on all\n        $p-1$ other variables\n    -   this metric tells us how much shared variation there is between\n        an item and all other items\n    -   This is one way to estimate a communalities (see later)\n-   There are also some statistical test (e.g. Bartlett's test)\n    -   However, these tests are generally not that informative.\n\n## Estimation\n\n-   For PCA, we discussed the use of the eigen-decomposition.\n    -   This is not an estimation method, it is simply a calculation\n-   As we have a model for the data in factor analysis, we need to\n    estimate the model parameters\n    -   primarily here the factor loading's.\n\n## Estimation & Communalities\n\nThe most efficient way to factor analyze data is to start by estimating\ncommunalities\n\n-   Communalities are estimates of how much true variance any variable\n    has\n\n    -   Indicate how much variance in an item is explained by other\n        variables, or factors\n\n-   If we consider that EFA is trying to explain true common variance,\n    then communalitie estimates are more useful to us than total\n    variance.\n\n-   Estimating communalities is difficult because population\n    communalities are unknown\n\n    -   Range from 0 (no shared variance) to 1 (all variance is shared)\n    -   Occasionally estimates will be $\\ge 1$ (called a 'Heywood Case')\n    -   Methods often are iterative and \"mechanical\" as a result\n\n## Principal axis factoring\n\nThis approach to EFA uses squared multiple correlation (SMC)\n\n1.  Compute initial communalities from SMCs\n2.  Once we have these reasonable lower bounds, we substitute the 1s in\n    the diagonal of our correlation matrix with the SMCs derived in step\n    1\n3.  Obtain the factor loading matrix using the eigenvalues and\n    eigenvectors of the matrix obtained in the step 2\n\nSome versions of principal axis factor use an iterative approach in\nwhich they replace the diagonal with the communalities obtained in step\n3, and then repeat step 3, and so on, a set number of times\n\n## Method of minimum residuals\n\nThis is an iterative approach and the default of the `fa` procedure\n\n1.  Starts with some other solution, e.g., PCA or principal axes,\n    extracting a set number of factors\n2.  Adjusts loading's of all factors on each variable so as to minimize\n    the residual correlations for that variable\n\nMINRES doesn't \"try\" to estimate communalities.\\\nIf you apply principal axis factoring to the original correlation matrix\nwith a diagonal of communalities derived from step 2, you get the same\nfactors as in the method of minimum residuals\n\n## Maximum likelihood estimation\n\nUses a general iterative procedure for estimating parameters that we\nhave previously discussed.\n\nThe procedure works to find values for these parameters that maximize\nthe likelihood of obtaining the covariance matrix\n\n-   Method offers the advantage of providing numerous \"fit\" statistics\n    that you can use to evaluate how good your model is compared to\n    alternative models\n    -   Recall we can compare the model implied to the actual\n        covariances to get fit.\n-   Assumes a distribution for your data, e.g., a normal distribution\n\n## ML con's\n\nThe issue is that for big analyses, sometimes it is not possible to find\nvalues for factor loadings that = MLE estimates. + Referred to as\nnon-convergence (you may see warnings)\n\nMay produce solutions with impossible values + Factor loadings \\> 1.00\n(Heywood cases), thus negative residuals. + Factor correlations \\> 1.00\n\n## Non-continuous data\n\n-   Sometimes the construct we are interested in is not continuous, e.g.\n    number of crimes committed.\n\n-   Sometimes we assume the construct is, but we measure it with a\n    discrete scale.\n\n-   Most constructs we seek to measure by questionnaire fall into the\n    latter category.\n\n    -   It's thus *usually* okay to treat the data as if they are, too\n    -   The exception is for maximum likelihood factor analysis\n    -   Or if the observed distribution is very skewed\n\n## Non-continuous data\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-9-1.png){width=670}\n:::\n:::\n\n\n## Non-continuous data\n\n-   If we are concerned and the construct is normally distributed, we\n    can conduct our analysis on a matrix of polychoric correlations\n\n-   If the construct is not normally distributed, you can conduct a\n    factor analysis that allows for these kinds of variables\n\n## Choosing an estimator\n\n-   The best option, as with many statistical models, is ML.\n\n-   If ML solutions fail to converge, principal axis is a simple\n    approach which typically yields reliable results.\n\n-   If concerns over the distribution of variables, use PAF on the\n    polychoric correlations.\n\n## Number of factors {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\nWe have discussed the methods for deciding on the number of factors in\nthe context of PCA.\n\nRecall we have 4 tools:\n\n-   Variance explained\n-   Scree plots\n-   MAP\n-   Parallel Analysis (FA or PCA)\n:::\n\n::: {.column .fragment width=\"50%\"}\nFor FA, we generally want a slightly more nuanced approach than pure\nvariance:\n\n-   Use them all to provide a range of plausible number of factors\n-   Treat MAP as a minimum\n-   PA as a maximum\n-   Explore all solutions in this range and select the one that yields\n    the best numerically and theoretically.\n:::\n:::\n\n# Factor rotation\n\n## Factor rotation: what and why?\n\nFactor solutions can sometimes be complex to interpret.\n\n-   the pattern of the factor loading's is not clear.\n-   The difference between the primary and cross-loading's is small\n\nWhy is this the case?\n\n-   **Rotational indeterminacy** means that there are an infinite number\n    of pairs of factor loading's and factor score matrices which will\n    fit the data **equally well**, and are thus **indistinguishable** by\n    any numeric criteria\n\n-   In other words, there is no **unique solution** to the factor\n    problem\n\n-   And this is also in part why the theoretical coherence of the models\n    plays a much bigger role in FA than PCA.\n\n## Analytic rotation\n\n-   Factor rotation is an approach to clarifying the relationships\n    between items and factors.\n\n    -   Rotation aims to maximize the relationship of a measured item\n        with a factor.\n    -   That is, make the primary loading big and cross-loading's small.\n\n-   Thus although we can not numerically tell rotated solutions apart,\n    we can select the one with the most coherent solution.\n\n-   There are many different ways this can be achieved.\n\n    -   One framework for this is referred to as **simple structure**\n\n## Simple structure\n\nAdapted from Sass and Schmitt (2011):\n\n1.  Each variable (row) should have at least one zero loading\n\n2.  Each factor (column) should have same number of zeroâ€™s as there are\n    factors\n\n3.  Every pair of factors (columns) should have several variables which\n    load on one factor, but not the other\n\n4.  Whenever more than four factors are extracted, each pair of factors\n    (columns) should have a large proportion of variables which do not\n    load on either factor\n\n5.  Every pair of factors should have few variables which load on both\n    factors\n\n## Orthogonal vs Oblique Rotation\n\n-   All factor rotation methods seek to optimize one or more aspects of\n    simple structure.\n\n    -   But there are two broad groupings\n\n-   Orthogonal + Includes varimax and quartimax rotations + Axes at\n    right angles; correlations between factors are zero\n\n-   Oblique\n\n    -   Includes promax and oblimin rotations\n    -   Axes are not at right angles; correlations between factors are\n        not zero\n\n## The impact of rotation\n\n::: columns\n::: {.column width=\"50%\"}\n**Original correlations**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-10-1.svg)\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**EFA with no rotation and 5 factors**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-11-1.svg)\n:::\n:::\n\n:::\n:::\n\n## The impact of rotation\n\n::: columns\n::: {.column width=\"50%\"}\n**EFA with no rotation and 5 factors**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-12-1.svg)\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**EFA with orthogonal rotation and 5 factors**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-13-1.svg)\n:::\n:::\n\n:::\n:::\n\n## The impact of rotation\n\n::: columns\n::: {.column width=\"50%\"}\n**EFA with orthogonal rotation and 5 factors**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-14-1.svg)\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**EFA with oblique rotation and 5 factors**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09efa_files/figure-revealjs/unnamed-chunk-15-1.svg)\n:::\n:::\n\n:::\n:::\n\n## How do I choose which rotation?\n\n-   Easy, my recommendation is always to choose oblique.\n\n-   Why?\n\n    -   It is very unlikely factors have correlations of 0\n    -   If they are close to zero, this is allowed within oblique\n        rotation\n    -   The whole approach is exploratory, and the constraint is\n        unnecessary.\n\n-   However, there is a catch...\n\n## Interpretation and oblique rotation\n\n-   When we have an obliquely rotated solution, we need to draw a\n    distinction between the **pattern** and **structure** matrix.\n\n    -   Pattern Matrix: matrix of regression weights (loading's) from\n        factors to variables.\n    -   Structure Matrix: matrix of correlations between factors and\n        variables.\n\n-   When we use orthogonal rotation, the pattern and structure matrix\n    are the same.\n\n-   When we use oblique rotation, the structure matrix is the pattern\n    matrix multiplied by the factor correlations.\n\n-   In most practical situations, this does not impact what we do, but\n    it is important to highlight the distinction.\n\n# Example and interpretation\n\n## Worked Example\n\n-   In this weeks LEARN folder there is a worked example of an EFA.\n",
    "supporting": [
      "09efa_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}